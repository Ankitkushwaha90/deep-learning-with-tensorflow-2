{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"5eMMJssyxQ-J"},"outputs":[],"source":["#!pip install --upgrade tensorflow"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C24JKO7LxP3O"},"outputs":[],"source":["import tensorflow as tf### models\n","import numpy as np### math computations\n","import matplotlib.pyplot as plt### plotting bar chart\n","import sklearn### machine learning library\n","import cv2## image processing\n","from sklearn.metrics import confusion_matrix, roc_curve### metrics\n","import seaborn as sns### visualizations\n","import datetime\n","import pathlib\n","import io\n","import os\n","import re\n","import string\n","import time\n","from numpy import random\n","import tensorflow_datasets as tfds\n","import tensorflow_probability as tfp\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Layer\n","from tensorflow.keras.layers import (Dense,Flatten,SimpleRNN,InputLayer,Conv1D,LayerNormalization,Bidirectional,GRU,LSTM,BatchNormalization,Dropout,Input,MultiHeadAttention,Embedding,TextVectorization)\n","from tensorflow.keras.losses import BinaryCrossentropy,CategoricalCrossentropy, SparseCategoricalCrossentropy\n","from tensorflow.keras.metrics import Accuracy,TopKCategoricalAccuracy, CategoricalAccuracy, SparseCategoricalAccuracy\n","from tensorflow.keras.optimizers import Adam\n","from google.colab import drive\n","from google.colab import files\n","from tensorboard.plugins import projector"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":106,"status":"ok","timestamp":1663085828314,"user":{"displayName":"martins folefac","userId":"15114498789158493667"},"user_tz":-60},"id":"LdwxalEeyUX5","outputId":"a6195455-1e21-4fbd-8d40-324f40d4c431"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'2.8.2'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":2}],"source":["tf.__version__"]},{"cell_type":"markdown","metadata":{"id":"cKg0HdsrYA0S"},"source":["# Data Preparation"]},{"cell_type":"markdown","metadata":{"id":"WgU1Z8fcOSW_"},"source":["## Data Download"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":434,"status":"ok","timestamp":1663085828649,"user":{"displayName":"martins folefac","userId":"15114498789158493667"},"user_tz":-60},"id":"4hwhov2uvDdo","outputId":"dd2bb197-be5b-4a55-f6fd-cb84bb33792b"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-09-13 16:17:47--  https://www.manythings.org/anki/fra-eng.zip\n","Resolving www.manythings.org (www.manythings.org)... 173.254.30.110\n","Connecting to www.manythings.org (www.manythings.org)|173.254.30.110|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 6720195 (6.4M) [application/zip]\n","Saving to: ‘fra-eng.zip’\n","\n","fra-eng.zip         100%[===================>]   6.41M  15.2MB/s    in 0.4s    \n","\n","2022-09-13 16:17:48 (15.2 MB/s) - ‘fra-eng.zip’ saved [6720195/6720195]\n","\n"]}],"source":["!wget https://www.manythings.org/anki/fra-eng.zip"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":39,"status":"ok","timestamp":1663085828649,"user":{"displayName":"martins folefac","userId":"15114498789158493667"},"user_tz":-60},"id":"Y-ufBPwn8_ax","outputId":"43e82a80-1399-4a42-9a88-fcac2eb25504"},"outputs":[{"output_type":"stream","name":"stdout","text":["Archive:  /content/fra-eng.zip\n","  inflating: /content/dataset/_about.txt  \n","  inflating: /content/dataset/fra.txt  \n"]}],"source":["!unzip \"/content/fra-eng.zip\" -d \"/content/dataset/\""]},{"cell_type":"markdown","metadata":{"id":"RBHsJDpiYDs7"},"source":["## Kaggle Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5672,"status":"ok","timestamp":1662593103382,"user":{"displayName":"martins folefac","userId":"15114498789158493667"},"user_tz":-60},"id":"0Lako-uhxy-n","outputId":"6a9ace35-3303-4b87-9c62-e546b7cfb26d"},"outputs":[{"name":"stdout","output_type":"stream","text":["cp: cannot stat 'kaggle.json': No such file or directory\n","chmod: cannot access '/root/.kaggle/kaggle.json': No such file or directory\n","Traceback (most recent call last):\n","  File \"/usr/local/bin/kaggle\", line 5, in <module>\n","    from kaggle.cli import main\n","  File \"/usr/local/lib/python3.7/dist-packages/kaggle/__init__.py\", line 23, in <module>\n","    api.authenticate()\n","  File \"/usr/local/lib/python3.7/dist-packages/kaggle/api/kaggle_api_extended.py\", line 166, in authenticate\n","    self.config_file, self.config_dir))\n","OSError: Could not find kaggle.json. Make sure it's located in /root/.kaggle. Or use the environment method.\n"]}],"source":["!pip install -q kaggle\n","!mkdir ~/.kaggle\n","!cp kaggle.json ~/.kaggle/\n","!chmod 600 /root/.kaggle/kaggle.json\n","!kaggle datasets download -d dhruvildave/en-fr-translation-dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":85198,"status":"ok","timestamp":1661936882170,"user":{"displayName":"martins folefac","userId":"15114498789158493667"},"user_tz":-60},"id":"B44hfX_vxzA-","outputId":"a7ea748a-6a24-4941-d2d0-5242b597f574"},"outputs":[{"name":"stdout","output_type":"stream","text":["Archive:  /content/en-fr-translation-dataset.zip\n","  inflating: /content/dataset/en-fr.csv  \n"]}],"source":["!unzip \"/content/en-fr-translation-dataset.zip\" -d \"/content/dataset/\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fXcOEWp2L7U9"},"outputs":[],"source":["dataset = tf.data.experimental.CsvDataset(\n","  \"/content/dataset/en-fr.csv\",\n","  [\n","    tf.string,\n","    tf.string\n","  ],\n",")"]},{"cell_type":"markdown","metadata":{"id":"omyb2Dq_YHbT"},"source":["## Data Processing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ywC7WnoIJeXl"},"outputs":[],"source":["text_dataset=tf.data.TextLineDataset(\"/content/dataset/fra.txt\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QlcJxz6cJeb_"},"outputs":[],"source":["VOCAB_SIZE=20000\n","ENGLISH_SEQUENCE_LENGTH=64\n","FRENCH_SEQUENCE_LENGTH=64\n","EMBEDDING_DIM=256\n","BATCH_SIZE=64"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TePer9o-JeeR"},"outputs":[],"source":["english_vectorize_layer=TextVectorization(\n","    standardize='lower_and_strip_punctuation',\n","    max_tokens=VOCAB_SIZE,\n","    output_mode='int',\n","    output_sequence_length=ENGLISH_SEQUENCE_LENGTH\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"unGn0zqEJegg"},"outputs":[],"source":["french_vectorize_layer=TextVectorization(\n","    standardize='lower_and_strip_punctuation',\n","    max_tokens=VOCAB_SIZE,\n","    output_mode='int',\n","    output_sequence_length=FRENCH_SEQUENCE_LENGTH\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iNK3uewuQTjY"},"outputs":[],"source":["def selector(input_text):\n","  split_text=tf.strings.split(input_text,'\\t')\n","  return {'input_1':split_text[0:1],'input_2':'starttoken '+split_text[1:2]},split_text[1:2]+' endtoken'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YZDH8xn7Q12e"},"outputs":[],"source":["split_dataset=text_dataset.map(selector)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7fcSDED_2c-z"},"outputs":[],"source":["def separator(input_text):\n","  split_text=tf.strings.split(input_text,'\\t')\n","  return split_text[0:1],'starttoken '+split_text[1:2]+' endtoken'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ktN95hiN2pgU"},"outputs":[],"source":["init_dataset=text_dataset.map(separator)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":373,"status":"ok","timestamp":1663085833793,"user":{"displayName":"martins folefac","userId":"15114498789158493667"},"user_tz":-60},"id":"OQkSkpd1tils","outputId":"f7515b78-7c49-43bf-f683-d81ff3b712a1"},"outputs":[{"output_type":"stream","name":"stdout","text":["({'input_1': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Go.'], dtype=object)>, 'input_2': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'starttoken Va !'], dtype=object)>}, <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Va ! endtoken'], dtype=object)>)\n","({'input_1': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Go.'], dtype=object)>, 'input_2': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'starttoken Marche.'], dtype=object)>}, <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Marche. endtoken'], dtype=object)>)\n","({'input_1': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Go.'], dtype=object)>, 'input_2': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'starttoken En route !'], dtype=object)>}, <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'En route ! endtoken'], dtype=object)>)\n"]}],"source":["for i in split_dataset.take(3):\n","  print(i)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_usEDYiOJeil"},"outputs":[],"source":["english_training_data=init_dataset.map(lambda x,y:x)### input x,y and output x\n","english_vectorize_layer.adapt(english_training_data)#### adapt the vectorize_layer to the training data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dl7pxJprJek2"},"outputs":[],"source":["french_training_data=init_dataset.map(lambda x,y:y)### input x,y and output y\n","french_vectorize_layer.adapt(french_training_data)#### adapt the vectorize_layer to the training data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4yVIMxvTJemt"},"outputs":[],"source":["def vectorizer(inputs,output):\n","  return {'input_1':english_vectorize_layer(inputs['input_1']),\n","          'input_2':french_vectorize_layer(inputs['input_2'])},french_vectorize_layer(output)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1663086328047,"user":{"displayName":"martins folefac","userId":"15114498789158493667"},"user_tz":-60},"id":"op5UqhS14HHz","outputId":"71326288-e352-42f0-f454-1948e81b7af1"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<MapDataset element_spec=({'input_1': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'input_2': TensorSpec(shape=(None,), dtype=tf.string, name=None)}, TensorSpec(shape=(None,), dtype=tf.string, name=None))>"]},"metadata":{},"execution_count":17}],"source":["split_dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wI9-GPpVJepF"},"outputs":[],"source":["dataset=split_dataset.map(vectorizer)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25,"status":"ok","timestamp":1663086328540,"user":{"displayName":"martins folefac","userId":"15114498789158493667"},"user_tz":-60},"id":"m_6Xtks8wPk5","outputId":"51ab34e8-01c2-4875-8083-9464a7746f78"},"outputs":[{"output_type":"stream","name":"stdout","text":["({'input_1': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Go.'], dtype=object)>, 'input_2': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'starttoken Va !'], dtype=object)>}, <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Va ! endtoken'], dtype=object)>)\n","({'input_1': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Go.'], dtype=object)>, 'input_2': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'starttoken Marche.'], dtype=object)>}, <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Marche. endtoken'], dtype=object)>)\n","({'input_1': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Go.'], dtype=object)>, 'input_2': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'starttoken En route !'], dtype=object)>}, <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'En route ! endtoken'], dtype=object)>)\n"]}],"source":["for i in split_dataset.take(3):\n","  print(i)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1663086328540,"user":{"displayName":"martins folefac","userId":"15114498789158493667"},"user_tz":-60},"id":"FM9aenklufpC","outputId":"7645cce0-ff33-409d-80ea-7104299d4622"},"outputs":[{"output_type":"stream","name":"stdout","text":["({'input_1': <tf.Tensor: shape=(1, 64), dtype=int64, numpy=\n","array([[44,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]])>, 'input_2': <tf.Tensor: shape=(1, 64), dtype=int64, numpy=\n","array([[  2, 112,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]])>}, <tf.Tensor: shape=(1, 64), dtype=int64, numpy=\n","array([[112,   3,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]])>)\n"]}],"source":["for i in dataset.take(1):\n","  print(i)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1663086328541,"user":{"displayName":"martins folefac","userId":"15114498789158493667"},"user_tz":-60},"id":"iOpSsko7TiKd","outputId":"46cd5b70-3ac6-4e43-8c95-7c5120f07db0"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<MapDataset element_spec=({'input_1': TensorSpec(shape=(None, 64), dtype=tf.int64, name=None), 'input_2': TensorSpec(shape=(None, 64), dtype=tf.int64, name=None)}, TensorSpec(shape=(None, 64), dtype=tf.int64, name=None))>"]},"metadata":{},"execution_count":21}],"source":["dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_WE0s6p9TiM9"},"outputs":[],"source":["dataset=dataset.shuffle(2048).unbatch().batch(BATCH_SIZE).prefetch(buffer_size=tf.data.AUTOTUNE)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1663086328542,"user":{"displayName":"martins folefac","userId":"15114498789158493667"},"user_tz":-60},"id":"tTkF_Qu54QB5","outputId":"4ea925d8-8758-494f-feb8-336cfa4ef49a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<PrefetchDataset element_spec=({'input_1': TensorSpec(shape=(None, 64), dtype=tf.int64, name=None), 'input_2': TensorSpec(shape=(None, 64), dtype=tf.int64, name=None)}, TensorSpec(shape=(None, 64), dtype=tf.int64, name=None))>"]},"metadata":{},"execution_count":23}],"source":["dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K5JXDdrNtwRj"},"outputs":[],"source":["NUM_BATCHES=int(200000/BATCH_SIZE)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XQvg18V5TiO7"},"outputs":[],"source":["train_dataset=dataset.take(int(0.9*NUM_BATCHES))\n","val_dataset=dataset.skip(int(0.9*NUM_BATCHES))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1663086328544,"user":{"displayName":"martins folefac","userId":"15114498789158493667"},"user_tz":-60},"id":"tfCmn1DzTiRp","outputId":"07a2da12-2418-4c6b-aaf1-03d563329f20"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<TakeDataset element_spec=({'input_1': TensorSpec(shape=(None, 64), dtype=tf.int64, name=None), 'input_2': TensorSpec(shape=(None, 64), dtype=tf.int64, name=None)}, TensorSpec(shape=(None, 64), dtype=tf.int64, name=None))>"]},"metadata":{},"execution_count":26}],"source":["train_dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ku7L4gZJXgYY"},"outputs":[],"source":["#score=tf.einsum('ijk,ibk->ijb',query,key)"]},{"cell_type":"markdown","metadata":{"id":"nBVM2EB0Xh97"},"source":["# Modeling"]},{"cell_type":"markdown","metadata":{"id":"UXZLSM5pkS3w"},"source":["## Embedding"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c1_5MCwq0ARk"},"outputs":[],"source":["def positional_encoding(model_size,SEQUENCE_LENGTH):\n","  output=[]\n","  for pos in range(SEQUENCE_LENGTH):\n","    PE=np.zeros((model_size))\n","    for i in range(model_size):\n","      if i%2==0:\n","        PE[i]=np.sin(pos/(10000**(i/model_size)))\n","      else:\n","        PE[i]=np.cos(pos/(10000**((i-1)/model_size)))\n","    output.append(tf.expand_dims(PE,axis=0))\n","  out=tf.concat(output,axis=0)\n","  out=tf.expand_dims(out,axis=0)\n","  return tf.cast(out,dtype=tf.float32)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1663095643474,"user":{"displayName":"martins folefac","userId":"15114498789158493667"},"user_tz":-60},"id":"PD4gK6uLxY8B","outputId":"0a10f7aa-7555-4063-e00a-bacd870ecc4b"},"outputs":[{"output_type":"stream","name":"stdout","text":["(1, 64, 256)\n"]}],"source":["print(positional_encoding(256,64).shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZM8tUhJ9G0tH"},"outputs":[],"source":["class Embeddings(Layer):\n","  def __init__(self, sequence_length, vocab_size, embed_dim,):\n","    super(Embeddings, self).__init__()\n","    self.token_embeddings=Embedding(\n","        input_dim=vocab_size, output_dim=embed_dim)\n","    self.sequence_length = sequence_length\n","    self.vocab_size = vocab_size\n","    self.embed_dim = embed_dim\n","\n","  def call(self, inputs):\n","    embedded_tokens = self.token_embeddings(inputs)\n","    embedded_positions=positional_encoding(\n","        self.embed_dim,self.sequence_length)\n","    return embedded_tokens + embedded_positions\n","    \n","  def compute_mask(self, inputs, mask=None):\n","    return tf.math.not_equal(inputs, 0)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1663095644179,"user":{"displayName":"martins folefac","userId":"15114498789158493667"},"user_tz":-60},"id":"Sr0o-QcgD4xS","outputId":"a1321316-3b67-4d53-cef6-adf0a51e46e5"},"outputs":[{"output_type":"stream","name":"stdout","text":["(1, 8, 256)\n"]}],"source":["test_input=tf.constant([[  2, 112,   10,   12,  5,   0,   0,   0,]])\n","\n","emb=Embeddings(8,20000,256)\n","emb_out=emb(test_input)\n","print(emb_out.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":461,"status":"ok","timestamp":1663095645333,"user":{"displayName":"martins folefac","userId":"15114498789158493667"},"user_tz":-60},"id":"zoZ59gSaom6P","outputId":"6601e1d5-54ae-4fe5-bcc5-d00b7212915e"},"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor(\n","[[[0 0 0 0 0 1 1 1]\n","  [0 0 0 0 0 1 1 1]\n","  [0 0 0 0 0 1 1 1]\n","  [0 0 0 0 0 1 1 1]\n","  [0 0 0 0 0 1 1 1]\n","  [1 1 1 1 1 1 1 1]\n","  [1 1 1 1 1 1 1 1]\n","  [1 1 1 1 1 1 1 1]]], shape=(1, 8, 8), dtype=int32)\n"]}],"source":["mask=emb.compute_mask(test_input)\n","mask1 = mask[:, :, tf.newaxis]\n","mask2 = mask[:,tf.newaxis, :]\n","padding_mask = tf.cast(mask1&mask2, dtype=\"int32\")\n","print(1-padding_mask)"]},{"cell_type":"markdown","metadata":{"id":"QaDKmgJgklY_"},"source":["## Custom MultiHeadAttention"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AIRfhrVINS39"},"outputs":[],"source":["class CustomSelfAttention(Layer):\n","  def __init__(self,model_size):\n","    super(CustomSelfAttention,self).__init__()\n","    self.model_size=model_size\n","  def call(self,query,key,value,masking):\n","    ######## compute scores\n","    score=tf.matmul(query,key,transpose_b=True)\n","    ######## scaling\n","    score/=tf.math.sqrt(tf.cast(self.model_size,tf.float32))\n","    ######## masking\n","    masking=tf.cast(masking,dtype=tf.float32)\n","    score+=(1.-masking)*-1e10\n","    ######## attention_weights\n","    attention=tf.nn.softmax(score,axis=-1)*masking\n","    ######## output\n","    head=tf.matmul(attention,value)\n","    return head"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1500,"status":"ok","timestamp":1663067017647,"user":{"displayName":"martins folefac","userId":"15114498789158493667"},"user_tz":-60},"id":"LSqZtns6YdHP","outputId":"165e9d8b-6d89-4fa7-82a2-843d5e53a3f4"},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(1, 8, 256), dtype=float32, numpy=\n","array([[[1., 1., 1., ..., 1., 1., 1.],\n","        [1., 1., 1., ..., 1., 1., 1.],\n","        [1., 1., 1., ..., 1., 1., 1.],\n","        ...,\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)>"]},"execution_count":45,"metadata":{},"output_type":"execute_result"}],"source":["attention=CustomSelfAttention(256)\n","attention(tf.ones([1,8,256]),tf.ones([1,8,256]),tf.ones([1,8,256]),padding_mask)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6Unruv2vNS6g"},"outputs":[],"source":["class CustomMultiHeadAttention(Layer):\n","  def __init__(self,num_heads,key_dim):\n","    super(CustomMultiHeadAttention,self).__init__()\n","    \n","    self.num_heads=num_heads\n","    self.dense_q=[Dense(key_dim) for _ in range(num_heads)]\n","    self.dense_k=[Dense(key_dim) for _ in range(num_heads)]\n","    self.dense_v=[Dense(key_dim) for _ in range(num_heads)]\n","    self.dense_o=Dense(key_dim)\n","    self.self_attention=CustomSelfAttention(key_dim)\n","    \n","  def call(self,query,key,value,attention_mask):\n","    heads=[]\n","    \n","    for i in range(self.num_heads):\n","        head=self.self_attention(self.dense_q[i](query),self.dense_k[i](key),\n","                                self.dense_v[i](value),attention_mask)\n","        heads.append(head)\n","    heads=tf.concat(heads,axis=2)\n","    heads=self.dense_o(heads)\n","    return heads"]},{"cell_type":"markdown","metadata":{"id":"S-Y512TzkOKQ"},"source":["## Encoder"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2jvze09LsnAw"},"outputs":[],"source":["#?tf.keras.layers.MultiHeadAttention"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t5lTjZBE6M4Q"},"outputs":[],"source":["class TransformerEncoder(Layer):\n","    def __init__(self, embed_dim, dense_dim, num_heads,):\n","        super(TransformerEncoder, self).__init__()\n","        self.embed_dim = embed_dim\n","        self.dense_dim = dense_dim\n","        self.num_heads = num_heads\n","        self.attention = MultiHeadAttention(\n","            num_heads=num_heads, key_dim=embed_dim,\n","        )\n","        self.dense_proj=tf.keras.Sequential(\n","            [Dense(dense_dim, activation=\"relu\"),Dense(embed_dim),]\n","        )\n","        self.layernorm_1 = LayerNormalization()\n","        self.layernorm_2 = LayerNormalization()\n","        self.supports_masking = True\n","\n","    def call(self, inputs, mask=None):\n","      if mask is not None:\n","        mask1 = mask[:, :, tf.newaxis]\n","        mask2 = mask[:,tf.newaxis, :]\n","        padding_mask = tf.cast(mask1&mask2, dtype=\"int32\")\n","\n","      attention_output = self.attention(\n","          query=inputs, key=inputs,value=inputs,attention_mask=padding_mask\n","      )\n","      \n","      proj_input = self.layernorm_1(inputs + attention_output)\n","      proj_output = self.dense_proj(proj_input)\n","      return self.layernorm_2(proj_input + proj_output)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":417,"status":"ok","timestamp":1663095647735,"user":{"displayName":"martins folefac","userId":"15114498789158493667"},"user_tz":-60},"id":"hOgozN6bu3hv","outputId":"2a00177e-6129-4c5e-f516-3490e11d2d9c"},"outputs":[{"output_type":"stream","name":"stdout","text":["(1, 8, 256)\n"]}],"source":["encoder_outputs = TransformerEncoder(256,2048,2)(emb_out)\n","print(encoder_outputs.shape)\n"]},{"cell_type":"markdown","metadata":{"id":"jDTmNxkmkctq"},"source":["## Decoder"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kdHTwxmfHWZW"},"outputs":[],"source":["class TransformerDecoder(Layer):\n","  def __init__(self, embed_dim, latent_dim, num_heads,):\n","    super(TransformerDecoder, self).__init__()\n","    self.embed_dim = embed_dim\n","    self.latent_dim = latent_dim\n","    self.num_heads = num_heads\n","    self.attention_1=MultiHeadAttention(\n","        num_heads=num_heads, key_dim=embed_dim\n","    )\n","    self.attention_2=MultiHeadAttention(\n","        num_heads=num_heads, key_dim=embed_dim\n","    )\n","    self.dense_proj = tf.keras.Sequential(\n","        [Dense(latent_dim, activation=\"relu\"),Dense(embed_dim),]\n","    )\n","    self.layernorm_1=LayerNormalization()\n","    self.layernorm_2=LayerNormalization()\n","    self.layernorm_3=LayerNormalization()\n","    self.supports_masking = True\n","  def call(self, inputs, encoder_outputs, mask=None):\n","    \n","    if mask is not None:\n","      mask1 = mask[:, :, tf.newaxis]\n","      mask2 = mask[:,tf.newaxis, :]\n","      padding_mask = tf.cast(mask1&mask2, dtype=\"int32\")\n","      causal_mask=tf.linalg.band_part(tf.ones([tf.shape(inputs)[0],tf.shape(inputs)[1],\n","                                               tf.shape(inputs)[1]],dtype=tf.int32),-1,0)\n","      combined_mask=tf.minimum(padding_mask,causal_mask)\n","\n","    attention_output_1 = self.attention_1(\n","        query=inputs,key=inputs,value=inputs,\n","        attention_mask=causal_mask,\n","        \n","    )\n","    out_1 = self.layernorm_1(inputs + attention_output_1)\n","\n","    attention_output_2,scores= self.attention_2(\n","        query=out_1,key=encoder_outputs,value=encoder_outputs,\n","        attention_mask=combined_mask,\n","        return_attention_scores=True\n","    )\n","    out_2 = self.layernorm_2(out_1 + attention_output_2)\n","\n","    proj_output = self.dense_proj(out_2)\n","    return self.layernorm_3(out_2 + proj_output),scores"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1663095732660,"user":{"displayName":"martins folefac","userId":"15114498789158493667"},"user_tz":-60},"id":"bQ0i7k60eDGk","outputId":"6bdf89e0-a404-4d27-b8eb-63b5c3892919"},"outputs":[{"output_type":"stream","name":"stdout","text":["(1, 8, 256)\n","(1, 4, 8, 8)\n"]}],"source":["decoder_outputs,scores = TransformerDecoder(256,2048,4)(emb_out,encoder_outputs)\n","print(decoder_outputs.shape)\n","print(scores.shape)"]},{"cell_type":"markdown","metadata":{"id":"1SPdfBx8ke-Z"},"source":["## Transformer Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wsT7pvXfzh_E"},"outputs":[],"source":["EMBEDDING_DIM=128\n","D_FF=1024\n","NUM_HEADS=8\n","NUM_LAYERS=1\n","NUM_EPOCHS=20\n","attention_scores={}"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1878,"status":"ok","timestamp":1663096586753,"user":{"displayName":"martins folefac","userId":"15114498789158493667"},"user_tz":-60},"id":"-7_vJmd8HWbu","outputId":"49f84320-2aa2-45b9-81db-164bd863b90f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"transformer\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_1 (InputLayer)           [(None, None)]       0           []                               \n","                                                                                                  \n"," input_2 (InputLayer)           [(None, None)]       0           []                               \n","                                                                                                  \n"," embeddings_12 (Embeddings)     (None, 64, 128)      2560000     ['input_1[0][0]']                \n","                                                                                                  \n"," embeddings_13 (Embeddings)     (None, 64, 128)      2560000     ['input_2[0][0]']                \n","                                                                                                  \n"," transformer_encoder_7 (Transfo  (None, 64, 128)     791296      ['embeddings_12[0][0]']          \n"," rmerEncoder)                                                                                     \n","                                                                                                  \n"," transformer_decoder_11 (Transf  ((None, 64, 128),   1319040     ['embeddings_13[0][0]',          \n"," ormerDecoder)                   (None, 8, 64, 64))               'transformer_encoder_7[0][0]']  \n","                                                                                                  \n"," dense_45 (Dense)               (None, 64, 20000)    2580000     ['transformer_decoder_11[0][0]'] \n","                                                                                                  \n","==================================================================================================\n","Total params: 9,810,336\n","Trainable params: 9,810,336\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}],"source":["encoder_inputs=Input(shape=(None,), dtype=\"int64\", name=\"input_1\")\n","x = Embeddings(ENGLISH_SEQUENCE_LENGTH,VOCAB_SIZE,EMBEDDING_DIM)(encoder_inputs)\n","\n","for _ in range(NUM_LAYERS):\n","  x=TransformerEncoder(EMBEDDING_DIM,D_FF,NUM_HEADS)(x)\n","encoder_outputs=x\n","\n","decoder_inputs=Input(shape=(None,), dtype=\"int64\", name=\"input_2\")\n","\n","x = Embeddings(FRENCH_SEQUENCE_LENGTH,VOCAB_SIZE,EMBEDDING_DIM)(decoder_inputs)\n","for i in range(NUM_LAYERS):\n","  x,scores=TransformerDecoder(EMBEDDING_DIM,D_FF,NUM_HEADS)(x, encoder_outputs)\n","  attention_scores[f'decoder_layer{i+1}_block2']=scores\n","decoder_outputs=Dense(VOCAB_SIZE, activation=\"softmax\")(x)\n","\n","attention_score_model= tf.keras.Model(\n","    [encoder_inputs, decoder_inputs], attention_scores, name=\"atttention_score_model\"\n",")\n","transformer = tf.keras.Model(\n","    [encoder_inputs, decoder_inputs], decoder_outputs, name=\"transformer\"\n",")\n","transformer.summary()"]},{"cell_type":"markdown","metadata":{"id":"urO3w5e971Hp"},"source":["# Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aBb_YQFGaztF"},"outputs":[],"source":["class BLEU(tf.keras.metrics.Metric):\n","    def __init__(self,name='bleu_score'):\n","        super(BLEU,self).__init__()\n","        self.bleu_score=0\n","\n","    def update_state(self,y_true,y_pred,sample_weight=None):\n","      y_pred=tf.argmax(y_pred,-1)\n","      self.bleu_score=0\n","      for i,j in zip(y_pred,y_true):\n","        tf.autograph.experimental.set_loop_options()\n","\n","        total_words=tf.math.count_nonzero(i)\n","        total_matches=0\n","        for word in i:\n","          if word==0:\n","            break\n","          for q in range(len(j)):\n","            if j[q]==0:\n","              break\n","            if word==j[q]:\n","              total_matches+=1\n","              j=tf.boolean_mask(j,[False if y==q else True for y in range(len(j))])\n","              break\n","\n","        self.bleu_score+=total_matches/total_words\n","        \n","    def result(self):\n","        return self.bleu_score/BATCH_SIZE"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iAKCOX98HWd9"},"outputs":[],"source":["transformer.compile(\n","    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n","    optimizer=tf.keras.optimizers.Adam(2e-4),)\n","    #metrics=[BLEU()],\n","    #run_eagerly=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":485},"id":"2529VjOrVuGe","executionInfo":{"status":"error","timestamp":1663097191927,"user_tz":-60,"elapsed":602506,"user":{"displayName":"martins folefac","userId":"15114498789158493667"}},"outputId":"8a71c4b0-84b7-4122-d400-784a35e22b1f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","2812/2812 [==============================] - 170s 59ms/step - loss: 0.4194\n","Epoch 2/20\n","2812/2812 [==============================] - 167s 59ms/step - loss: 0.2455\n","Epoch 3/20\n","2812/2812 [==============================] - 167s 59ms/step - loss: 0.1820\n","Epoch 4/20\n"," 470/2812 [====>.........................] - ETA: 2:19 - loss: 0.1041"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-172-737c703cb35e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m#validation_data=val_dataset.take(300),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     epochs=NUM_EPOCHS)\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1387\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1389\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    436\u001b[0m     \"\"\"\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    295\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m       raise ValueError(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    316\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m       \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1104\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1107\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    561\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 914\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    915\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 914\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    915\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m       \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m     \u001b[0;31m# Strings, ragged and sparse tensors don't have .item(). Return them as-is.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1221\u001b[0m     \"\"\"\n\u001b[1;32m   1222\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1223\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1224\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1187\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1190\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["history=transformer.fit(\n","    train_dataset,\n","    validation_data=val_dataset.take(300),\n","    epochs=NUM_EPOCHS)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rj3wLwSW7EMb"},"outputs":[],"source":["plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('model_loss')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'val'], loc='upper left')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pWJfUFU9VrQx"},"outputs":[],"source":["transformer.evaluate(val_dataset)"]},{"cell_type":"markdown","metadata":{"id":"4i1ajAymaDoF"},"source":["# Testing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b5vMnTM62Cx_"},"outputs":[],"source":["index_to_word={x:y for x, y in zip(range(len(french_vectorize_layer.get_vocabulary())),\n","                                   french_vectorize_layer.get_vocabulary())}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HiWzshkMKfQg"},"outputs":[],"source":["def translator(english_sentence):\n","  tokenized_english_sentence=english_vectorize_layer([english_sentence])\n","  shifted_target='starttoken'\n","\n","  for i in range(FRENCH_SEQUENCE_LENGTH):\n","    tokenized_shifted_target=french_vectorize_layer([shifted_target])\n","    output=transformer.predict([tokenized_english_sentence,tokenized_shifted_target])\n","    french_word_index=tf.argmax(output,axis=-1)[0][i].numpy()\n","    current_word=index_to_word[french_word_index]\n","    if current_word=='endtoken':\n","      break\n","    shifted_target+=' '+current_word\n","  return shifted_target[11:]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0RYy2vtxKfS7","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1663082578728,"user_tz":-60,"elapsed":666,"user":{"displayName":"martins folefac","userId":"15114498789158493667"}},"outputId":"e97a0845-c66b-4f9f-bbf3-bdbd0b2f845b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'questce qui te fait croire que ce nest pas vrai'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":48}],"source":["translator('What makes you think that it is not true?')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":935,"status":"ok","timestamp":1663082579658,"user":{"displayName":"martins folefac","userId":"15114498789158493667"},"user_tz":-60},"id":"f1BQFbrdKfVZ","outputId":"9c94d949-add6-4bf1-ef45-a861f065c945"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'astu regardé français à luniversité sous la pluie'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":49}],"source":["translator('Have you ever watched soccer under the rain?')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1663082579660,"user":{"displayName":"martins folefac","userId":"15114498789158493667"},"user_tz":-60},"id":"je_d1YvagbZO","outputId":"2bf6a110-ad7b-4911-928e-5adae5a459d7"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'comment se nomme ton nom'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":50}],"source":["translator(\"what's your name?\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":420,"status":"ok","timestamp":1663082580068,"user":{"displayName":"martins folefac","userId":"15114498789158493667"},"user_tz":-60},"id":"jWoISRgEVM_J","outputId":"b7a9d12e-ecf5-44f1-f378-d222ff99b46a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'les arbres ne font plus pousser sur les autres'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":51}],"source":["translator('Great trees do not grow with ease, the stronger the winds, the stronger the trees')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":41279,"status":"ok","timestamp":1663082621340,"user":{"displayName":"martins folefac","userId":"15114498789158493667"},"user_tz":-60},"id":"BtuuqPkgVNB0","outputId":"22924cab-44bf-4f8f-fdde-a0a693bf7b58"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'mon hôtel ma dit de mappeler'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":52}],"source":["translator('My hotel told me to call you. ')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":449,"status":"ok","timestamp":1663082621773,"user":{"displayName":"martins folefac","userId":"15114498789158493667"},"user_tz":-60},"id":"levLKdrZerPj","outputId":"7637d6ff-3c4a-4a5a-b327-36db672af553"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'son français saméliore petit'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":53}],"source":["translator('His French is improving little by little')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1663082621777,"user":{"displayName":"martins folefac","userId":"15114498789158493667"},"user_tz":-60},"id":"jFEqsF4AerR3","outputId":"5b01528e-b1ac-44a9-ef63-a460d423e394"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'jadore écrire à écrire'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":54}],"source":["translator('I love to write')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":403,"status":"ok","timestamp":1663082622168,"user":{"displayName":"martins folefac","userId":"15114498789158493667"},"user_tz":-60},"id":"_27Gta23erUa","outputId":"8d0b2fae-1852-415e-a789-0228f465ebc3"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'peutêtre quelle viendra demain'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":55}],"source":["translator('Perhaps she will come tomorrow')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":1324,"status":"ok","timestamp":1663082623486,"user":{"displayName":"martins folefac","userId":"15114498789158493667"},"user_tz":-60},"id":"d1FizaA6erXE","outputId":"e2031d22-5b78-4daf-80ae-d3d5f7c3479f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'tom na jamais entendu marie chanter'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":56}],"source":["translator('Tom has never heard Mary sing.')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":20,"status":"ok","timestamp":1663082623488,"user":{"displayName":"martins folefac","userId":"15114498789158493667"},"user_tz":-60},"id":"fekzqiwGerZd","outputId":"6d1528e8-9d9c-4740-b618-6581dcc79feb"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'elle lui donna largent'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":57}],"source":["translator('She handed him the money')"]},{"cell_type":"code","source":[],"metadata":{"id":"lVMdXSi9d2Tx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Visualization"],"metadata":{"id":"5-dufWz8d2k_"}},{"cell_type":"code","source":["def visualize(english_sentence):\n","  tokenized_english_sentence=english_vectorize_layer([english_sentence])\n","  shifted_target='starttoken je lai fait très bien'\n","\n","  tokenized_shifted_target=french_vectorize_layer([shifted_target])\n","  attention_weights=attention_score_model.predict([tokenized_english_sentence,\n","                                                   tokenized_shifted_target])\n","    \n","  return attention_weights\n","\n","out=visualize('I did it very well')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0-d86MTK3gJ0","executionInfo":{"status":"ok","timestamp":1663097210873,"user_tz":-60,"elapsed":2030,"user":{"displayName":"martins folefac","userId":"15114498789158493667"}},"outputId":"aff68747-9e08-405d-fac6-e9b00ff3508b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:5 out of the last 26 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f1de559c830> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]}]},{"cell_type":"code","source":["print(out['decoder_layer1_block2'][0].shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4G2b6i3APj7I","executionInfo":{"status":"ok","timestamp":1663097210878,"user_tz":-60,"elapsed":13,"user":{"displayName":"martins folefac","userId":"15114498789158493667"}},"outputId":"b9c1db3f-9bd1-477f-ba16-3a223f05c92e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(8, 64, 64)\n"]}]},{"cell_type":"code","source":["plt.figure(figsize = (12,12))\n","\n","for i in range(NUM_HEADS):\n","  ax = plt.subplot(2,4, i+1)\n","  \n","  plt.imshow(out['decoder_layer1_block2'][0][i][0:10,0:10])\n","  plt.title(\"Attention Scores for head:->\"+str(i+1))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":565},"id":"dhg9F90xPkA0","executionInfo":{"status":"ok","timestamp":1663097667630,"user_tz":-60,"elapsed":2158,"user":{"displayName":"martins folefac","userId":"15114498789158493667"}},"outputId":"0e480fc9-9291-4125-9a6b-405d3b054265"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 864x864 with 8 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":[],"metadata":{"id":"kfo16S7IPkCn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"UQrTxW7kDUki"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"XJ9KjorWDUnL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"1KTaNE-pDUqj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"A2lMBYRIDUsK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"wy3nS93-DUt_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"1jHU34XoDUvu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"h3i6BLkADUyF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"itHuHsMeDU03"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"YeDY5DfGDU3e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ISPzJXr4DU7S"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":7676,"status":"ok","timestamp":1662630852599,"user":{"displayName":"martins folefac","userId":"15114498789158493667"},"user_tz":-60},"id":"Hrc4k-JQRnvf","outputId":"d4bab904-3a29-47e9-fb17-490bcc77ddd1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting aicrowd-cli\n","  Downloading aicrowd_cli-0.1.15-py3-none-any.whl (51 kB)\n","\u001b[K     |████████████████████████████████| 51 kB 4.0 MB/s \n","\u001b[?25hCollecting semver<3,>=2.13.0\n","  Downloading semver-2.13.0-py2.py3-none-any.whl (12 kB)\n","Collecting requests<3,>=2.25.1\n","  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n","\u001b[K     |████████████████████████████████| 62 kB 1.7 MB/s \n","\u001b[?25hCollecting pyzmq==22.1.0\n","  Downloading pyzmq-22.1.0-cp37-cp37m-manylinux1_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 44.1 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm<5,>=4.56.0 in /usr/local/lib/python3.7/dist-packages (from aicrowd-cli) (4.64.0)\n","Collecting GitPython==3.1.18\n","  Downloading GitPython-3.1.18-py3-none-any.whl (170 kB)\n","\u001b[K     |████████████████████████████████| 170 kB 72.7 MB/s \n","\u001b[?25hRequirement already satisfied: click<8,>=7.1.2 in /usr/local/lib/python3.7/dist-packages (from aicrowd-cli) (7.1.2)\n","Collecting rich<11,>=10.0.0\n","  Downloading rich-10.16.2-py3-none-any.whl (214 kB)\n","\u001b[K     |████████████████████████████████| 214 kB 61.2 MB/s \n","\u001b[?25hRequirement already satisfied: toml<1,>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from aicrowd-cli) (0.10.2)\n","Collecting requests-toolbelt<1,>=0.9.1\n","  Downloading requests_toolbelt-0.9.1-py2.py3-none-any.whl (54 kB)\n","\u001b[K     |████████████████████████████████| 54 kB 3.5 MB/s \n","\u001b[?25hCollecting python-slugify<6,>=5.0.0\n","  Downloading python_slugify-5.0.2-py2.py3-none-any.whl (6.7 kB)\n","Requirement already satisfied: typing-extensions>=3.7.4.0 in /usr/local/lib/python3.7/dist-packages (from GitPython==3.1.18->aicrowd-cli) (4.1.1)\n","Collecting gitdb<5,>=4.0.1\n","  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n","\u001b[K     |████████████████████████████████| 63 kB 2.3 MB/s \n","\u001b[?25hCollecting smmap<6,>=3.0.1\n","  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify<6,>=5.0.0->aicrowd-cli) (1.3)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.25.1->aicrowd-cli) (2.10)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.25.1->aicrowd-cli) (1.24.3)\n","Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.25.1->aicrowd-cli) (2.1.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.25.1->aicrowd-cli) (2022.6.15)\n","Collecting commonmark<0.10.0,>=0.9.0\n","  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n","\u001b[K     |████████████████████████████████| 51 kB 7.9 MB/s \n","\u001b[?25hRequirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from rich<11,>=10.0.0->aicrowd-cli) (2.6.1)\n","Collecting colorama<0.5.0,>=0.4.0\n","  Downloading colorama-0.4.5-py2.py3-none-any.whl (16 kB)\n","Installing collected packages: smmap, requests, gitdb, commonmark, colorama, semver, rich, requests-toolbelt, pyzmq, python-slugify, GitPython, aicrowd-cli\n","  Attempting uninstall: requests\n","    Found existing installation: requests 2.23.0\n","    Uninstalling requests-2.23.0:\n","      Successfully uninstalled requests-2.23.0\n","  Attempting uninstall: pyzmq\n","    Found existing installation: pyzmq 23.2.1\n","    Uninstalling pyzmq-23.2.1:\n","      Successfully uninstalled pyzmq-23.2.1\n","  Attempting uninstall: python-slugify\n","    Found existing installation: python-slugify 6.1.2\n","    Uninstalling python-slugify-6.1.2:\n","      Successfully uninstalled python-slugify-6.1.2\n","Successfully installed GitPython-3.1.18 aicrowd-cli-0.1.15 colorama-0.4.5 commonmark-0.9.1 gitdb-4.0.9 python-slugify-5.0.2 pyzmq-22.1.0 requests-2.28.1 requests-toolbelt-0.9.1 rich-10.16.2 semver-2.13.0 smmap-5.0.0\n"]},{"data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["zmq"]}}},"metadata":{},"output_type":"display_data"}],"source":["!pip install aicrowd-cli"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18216,"status":"ok","timestamp":1662631188825,"user":{"displayName":"martins folefac","userId":"15114498789158493667"},"user_tz":-60},"id":"J1Mz0vBYRn10","outputId":"e3b63ceb-75c7-48a5-e607-a1c72ea6f4a7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Please login here: \u001b[34m\u001b[1m\u001b[4mhttps://api.aicrowd.com/auth/wtHm9oiaN9-I--I4Ivn1eRDGXB7IG6YYX1nlj37hllk\u001b[0m\n","/usr/bin/xdg-open: 851: /usr/bin/xdg-open: www-browser: not found\n","/usr/bin/xdg-open: 851: /usr/bin/xdg-open: links2: not found\n","/usr/bin/xdg-open: 851: /usr/bin/xdg-open: elinks: not found\n","/usr/bin/xdg-open: 851: /usr/bin/xdg-open: links: not found\n","/usr/bin/xdg-open: 851: /usr/bin/xdg-open: lynx: not found\n","/usr/bin/xdg-open: 851: /usr/bin/xdg-open: w3m: not found\n","xdg-open: no method available for opening 'https://api.aicrowd.com/auth/wtHm9oiaN9-I--I4Ivn1eRDGXB7IG6YYX1nlj37hllk'\n","\u001b[32mAPI Key valid\u001b[0m\n","\u001b[32mGitlab access token valid\u001b[0m\n","\u001b[32mSaved details successfully!\u001b[0m\n"]}],"source":["!aicrowd login"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":113235,"status":"ok","timestamp":1662631305346,"user":{"displayName":"martins folefac","userId":"15114498789158493667"},"user_tz":-60},"id":"uy1kf4nlRnyI","outputId":"3c9c08b5-2687-4c2a-b14d-1fc840484c25"},"outputs":[{"name":"stdout","output_type":"stream","text":["product_catalogue-v0.3.csv.zip: 100% 328M/328M [00:16<00:00, 20.1MB/s]\n","sample_submission_public-v0.3.csv.zip: 100% 331k/331k [00:00<00:00, 587kB/s]\n","test_public-v0.3.csv.zip: 100% 394k/394k [00:00<00:00, 690kB/s]\n","train-v0.3.csv.zip: 100% 6.80M/6.80M [00:01<00:00, 5.95MB/s]\n","product_catalogue-v0.3.csv.zip: 100% 657M/657M [00:31<00:00, 21.1MB/s]\n","sample_submission_public-v0.3.csv.zip: 100% 812k/812k [00:00<00:00, 1.15MB/s]\n","test_public-v0.3.csv.zip: 100% 2.94M/2.94M [00:01<00:00, 2.94MB/s]\n","train-v0.3.csv.zip: 100% 19.8M/19.8M [00:01<00:00, 11.4MB/s]\n","product_catalogue-v0.3.csv.zip: 100% 657M/657M [00:42<00:00, 15.5MB/s]\n","sample_submission_public-v0.3.csv.zip: 100% 803k/803k [00:00<00:00, 1.12MB/s]\n","test_public-v0.3.csv.zip: 100% 2.94M/2.94M [00:00<00:00, 2.97MB/s]\n","train-v0.3.csv.zip: 100% 20.3M/20.3M [00:01<00:00, 10.9MB/s]\n"]}],"source":["!aicrowd dataset download -c esci-challenge-for-improving-product-search"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18750,"status":"ok","timestamp":1662631511971,"user":{"displayName":"martins folefac","userId":"15114498789158493667"},"user_tz":-60},"id":"pDg69tTsUlPv","outputId":"0247336a-a161-4e8f-a555-016a234eb01e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Archive:  /content/product_catalogue-v0.3.csv.zip\n","  inflating: /content/dataset/data/processed/public/task_3_product_substitute_identification/product_catalogue-v0.3.csv  \n"]}],"source":["!unzip \"/content/product_catalogue-v0.3.csv.zip\" -d \"/content/dataset/\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LEodr5PVUlWm"},"outputs":[],"source":["filepath='/content/dataset/data/processed/public/task_3_product_substitute_identification/product_catalogue-v0.3.csv'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EPiU6rQZUM10"},"outputs":[],"source":["import pandas as pd\n","\n","df = pd.read_csv(filepath)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":979,"status":"ok","timestamp":1662632701308,"user":{"displayName":"martins folefac","userId":"15114498789158493667"},"user_tz":-60},"id":"M3xcT3ReoYy1","outputId":"e5567f4a-9a87-41e7-fc58-655b7e5e957a"},"outputs":[{"data":{"text/plain":["1815216"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["len(df)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":10891},"executionInfo":{"elapsed":931,"status":"ok","timestamp":1662632738479,"user":{"displayName":"martins folefac","userId":"15114498789158493667"},"user_tz":-60},"id":"6AEeOkBQkZBu","outputId":"005492fc-5293-4e3d-cc78-9622b6e57f32"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-ad9d6df6-5366-4000-8cdf-ef5b2adf5d4f\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>product_id</th>\n","      <th>product_title</th>\n","      <th>product_description</th>\n","      <th>product_bullet_point</th>\n","      <th>product_brand</th>\n","      <th>product_color_name</th>\n","      <th>product_locale</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1600000</th>\n","      <td>B07RK154DV</td>\n","      <td>Stemless Wine Tumbler with Lid and Straw, Bast...</td>\n","      <td>&lt;b&gt;Bastwe 4 Pack 12oz Vacuum Insulated Wine Tu...</td>\n","      <td>💥 Food Grade Stainless Steel: The wine glass i...</td>\n","      <td>Bastwe</td>\n","      <td>Black</td>\n","      <td>us</td>\n","    </tr>\n","    <tr>\n","      <th>1600001</th>\n","      <td>B07T3SLJQ7</td>\n","      <td>PURECUP 12 oz Wine Tumbler With Spill-proof Li...</td>\n","      <td>&lt;b&gt;Specification:&lt;/b&gt;&lt;br&gt;*Designs: Stainless W...</td>\n","      <td>12OZ insulated stainless stell wine glasses wi...</td>\n","      <td>PURECUP</td>\n","      <td>Aqua Blue</td>\n","      <td>us</td>\n","    </tr>\n","    <tr>\n","      <th>1600002</th>\n","      <td>B07TF6JXSG</td>\n","      <td>Comfook Glass Bulk Set Wine Cups Glasses with ...</td>\n","      <td>NaN</td>\n","      <td>For Any Occasion: 12 oz glass is in a beautifu...</td>\n","      <td>Comfook</td>\n","      <td>Multicolor B</td>\n","      <td>us</td>\n","    </tr>\n","    <tr>\n","      <th>1600003</th>\n","      <td>B07VH1XG7J</td>\n","      <td>Deitybless 6 Pack 12 oz Stainless Steel Wine T...</td>\n","      <td>Deitybless pack wine tumbler cup with lids 12 ...</td>\n","      <td>【HIGHT QUALITY】The wine tumbler is made of goo...</td>\n","      <td>Deitybless</td>\n","      <td>Assorted Colors_6 pack(with straws)</td>\n","      <td>us</td>\n","    </tr>\n","    <tr>\n","      <th>1600004</th>\n","      <td>B0822R1N1K</td>\n","      <td>Vacuum Insulated Wine Tumbler with Sliding Lid...</td>\n","      <td>&lt;b&gt;LEVIN Vacuum Insulated Wine Tumbler with Sl...</td>\n","      <td>【Preserve the Most Wanted Temp &amp; Flavour】 Adop...</td>\n","      <td>LEVIN</td>\n","      <td>Black</td>\n","      <td>us</td>\n","    </tr>\n","    <tr>\n","      <th>1600005</th>\n","      <td>B082SC54BP</td>\n","      <td>MUCHENGHY 12 oz Wine Glass Tumbler Bulk with L...</td>\n","      <td>&lt;p&gt;Mucheng Vacuum Insulated Wine Tumbler with ...</td>\n","      <td>【GIVE AS A PRESENT TO COMMEMORATE!】 It's strik...</td>\n","      <td>MUCHENGHY</td>\n","      <td>Rose Gold</td>\n","      <td>us</td>\n","    </tr>\n","    <tr>\n","      <th>1600006</th>\n","      <td>B01M71BZD9</td>\n","      <td>Yedi 9-in-1 Total Package Instant Programmable...</td>\n","      <td>NaN</td>\n","      <td>OPRAH’S FAVORITE THINGS: The Yedi 9-in-1 Total...</td>\n","      <td>YEDI HOUSEWARE</td>\n","      <td>Stainless Steel</td>\n","      <td>us</td>\n","    </tr>\n","    <tr>\n","      <th>1600007</th>\n","      <td>B01NBKTPTS</td>\n","      <td>Instant Pot Duo Plus 6 Quart 9-in-1 Electric P...</td>\n","      <td>NaN</td>\n","      <td>SIMPLE, STRESS-FREE VENTING with an intuitive ...</td>\n","      <td>Instant Pot</td>\n","      <td>Stainless Steel/Black</td>\n","      <td>us</td>\n","    </tr>\n","    <tr>\n","      <th>1600008</th>\n","      <td>B0777XQ4S8</td>\n","      <td>Instant Pot Smart Wifi 6 Quart Multi-use Elect...</td>\n","      <td>NaN</td>\n","      <td>Cooks fast and saves time: The Instant Pot Sma...</td>\n","      <td>Instant Pot</td>\n","      <td>Silver</td>\n","      <td>us</td>\n","    </tr>\n","    <tr>\n","      <th>1600009</th>\n","      <td>B077T9YGRM</td>\n","      <td>Instant Pot Max 6 Quart Multi-use Electric Pre...</td>\n","      <td>NaN</td>\n","      <td>Sustained 15psi, not only cooks food faster, y...</td>\n","      <td>Instant Pot</td>\n","      <td>Silver</td>\n","      <td>us</td>\n","    </tr>\n","    <tr>\n","      <th>1600010</th>\n","      <td>B07LDJD3X5</td>\n","      <td>Instant Pot 8 QT Viva 9-in-1 Multi-Use Program...</td>\n","      <td>Instant Pot Viva 9 in 1 / New Product</td>\n","      <td>INSTANT POT\\nPressure Cooker</td>\n","      <td>Instant Pot</td>\n","      <td>NaN</td>\n","      <td>us</td>\n","    </tr>\n","    <tr>\n","      <th>1600011</th>\n","      <td>B07R4TMNXK</td>\n","      <td>prepAmeal 6QT 8 IN 1 Pressure Cooker MultiUse ...</td>\n","      <td>&lt;b&gt;There Pressure Settings&lt;/b&gt;&lt;br&gt; For fast an...</td>\n","      <td>8-IN-1 Multi-Functional Pot : 1 Electric Press...</td>\n","      <td>prepAmeal</td>\n","      <td>6 Quart</td>\n","      <td>us</td>\n","    </tr>\n","    <tr>\n","      <th>1600012</th>\n","      <td>B07VT23JDM</td>\n","      <td>Instant Pot Duo Crisp 11-in-1 Electric Pressur...</td>\n","      <td>NaN</td>\n","      <td>11-IN-1 FUNCTIONALITY: Air fry, roast, bake, d...</td>\n","      <td>Instant Pot</td>\n","      <td>Black/Stainless Steel</td>\n","      <td>us</td>\n","    </tr>\n","    <tr>\n","      <th>1600013</th>\n","      <td>B07WLJN9YZ</td>\n","      <td>Nuwave Nutri-Pot 13Qt Pressure Cooker</td>\n","      <td>Make a hearty beef stew in this Nutri-Pot digi...</td>\n","      <td>EVERYTHING YOU NEED- Your 13Q NutriPot Digital...</td>\n","      <td>NuWave</td>\n","      <td>NaN</td>\n","      <td>us</td>\n","    </tr>\n","    <tr>\n","      <th>1600014</th>\n","      <td>B087NSG5XB</td>\n","      <td>The Pioneer Woman Instant Pot DUO60 6-Quart Fr...</td>\n","      <td>SA</td>\n","      <td>NaN</td>\n","      <td>BATEMEN W</td>\n","      <td>11.28-WDBGM-1754</td>\n","      <td>us</td>\n","    </tr>\n","    <tr>\n","      <th>1600015</th>\n","      <td>B08SRS4TW2</td>\n","      <td>Instant Pot Ultra 10-in-1 Electric Pressure Co...</td>\n","      <td>NaN</td>\n","      <td>Product 1: For large families, 6+ people. Item...</td>\n","      <td>Instant Pot</td>\n","      <td>NaN</td>\n","      <td>us</td>\n","    </tr>\n","    <tr>\n","      <th>1600016</th>\n","      <td>B091CYX72J</td>\n","      <td>Tezam Reusable Air Fryer Liners – 7.5 Inch Squ...</td>\n","      <td>&lt;b&gt;Features:&lt;/b&gt;&lt;br&gt;&lt;p&gt; 1) 100% Reusable, Non-...</td>\n","      <td>NEW RELEASE! SAVE MONEY ON PARCHMENT PAPER or ...</td>\n","      <td>Tezam</td>\n","      <td>NaN</td>\n","      <td>us</td>\n","    </tr>\n","    <tr>\n","      <th>1600017</th>\n","      <td>0887276407</td>\n","      <td>Integrated Chinese Level 1 Part 1 Workbook: Si...</td>\n","      <td>NaN</td>\n","      <td>Used Book in Good Condition</td>\n","      <td>Brand: Cheng Tsui</td>\n","      <td>NaN</td>\n","      <td>us</td>\n","    </tr>\n","    <tr>\n","      <th>1600018</th>\n","      <td>0887276938</td>\n","      <td>Reading Into a New China: Integrated Skills fo...</td>\n","      <td>NaN</td>\n","      <td>Used Book in Good Condition</td>\n","      <td>Brand: Cheng Tsui</td>\n","      <td>NaN</td>\n","      <td>us</td>\n","    </tr>\n","    <tr>\n","      <th>1600019</th>\n","      <td>0976998130</td>\n","      <td>Japanese From Zero! 3: Proven Techniques to Le...</td>\n","      <td>NaN</td>\n","      <td>Used Book in Good Condition</td>\n","      <td>YesJapan Corporation</td>\n","      <td>NaN</td>\n","      <td>us</td>\n","    </tr>\n","    <tr>\n","      <th>1600020</th>\n","      <td>0989654524</td>\n","      <td>Korean From Zero! 1: Master the Korean Languag...</td>\n","      <td>NaN</td>\n","      <td>Yesjapan Corporation</td>\n","      <td>YesJapan Corporation</td>\n","      <td>NaN</td>\n","      <td>us</td>\n","    </tr>\n","    <tr>\n","      <th>1600021</th>\n","      <td>1091714746</td>\n","      <td>First Chinese Characters Book Easy Practice Wr...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Independently Published</td>\n","      <td>NaN</td>\n","      <td>us</td>\n","    </tr>\n","    <tr>\n","      <th>1600022</th>\n","      <td>1622911318</td>\n","      <td>Integrated Chinese 4th Edition, Volume 1 Workb...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>us</td>\n","    </tr>\n","    <tr>\n","      <th>1600023</th>\n","      <td>1622911350</td>\n","      <td>Integrated Chinese 4th Edition, Volume 1 Textb...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>us</td>\n","    </tr>\n","    <tr>\n","      <th>1600024</th>\n","      <td>1622911369</td>\n","      <td>Integrated Chinese 4th Edition, Volume 1 Workb...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>us</td>\n","    </tr>\n","    <tr>\n","      <th>1600025</th>\n","      <td>1622911377</td>\n","      <td>Integrated Chinese 4th Edition, Volume 1 Chara...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>us</td>\n","    </tr>\n","    <tr>\n","      <th>1600026</th>\n","      <td>1622911415</td>\n","      <td>Integrated Chinese 2 Textbook Simplified (Chin...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>us</td>\n","    </tr>\n","    <tr>\n","      <th>1600027</th>\n","      <td>1622911512</td>\n","      <td>Integrated Chinese Textbook Vol 4 (English and...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>us</td>\n","    </tr>\n","    <tr>\n","      <th>1600028</th>\n","      <td>1622911563</td>\n","      <td>Integrated Chinese Volume 3 Textbook, 4th edit...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>us</td>\n","    </tr>\n","    <tr>\n","      <th>1600029</th>\n","      <td>1622911571</td>\n","      <td>Integrated Chinese 3 Workbook, 4th edition (En...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>us</td>\n","    </tr>\n","    <tr>\n","      <th>1600030</th>\n","      <td>478901441X</td>\n","      <td>Genki: An Integrated Course in Elementary Japa...</td>\n","      <td>NaN</td>\n","      <td>◆Second edition of the most highly regarded te...</td>\n","      <td>Japan Times</td>\n","      <td>NaN</td>\n","      <td>us</td>\n","    </tr>\n","    <tr>\n","      <th>1600031</th>\n","      <td>4883196070</td>\n","      <td>Minna no Nihongo 2nd Edition Beginner vol.1 Bu...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>3A CORPORATION</td>\n","      <td>NaN</td>\n","      <td>us</td>\n","    </tr>\n","    <tr>\n","      <th>1600032</th>\n","      <td>B07ZH25X3N</td>\n","      <td>Advanced Hematology in Integrated Cardiovascul...</td>\n","      <td>&lt;p&gt;&lt;i&gt;Advanced Hematology in Integrative Cardi...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>us</td>\n","    </tr>\n","    <tr>\n","      <th>1600033</th>\n","      <td>B073XGDFY9</td>\n","      <td>Intel Xeon Gold 5120 Tray Processor</td>\n","      <td>Intel 2.2GHz Xeon Gold 5120 14-core FCLGA3647 ...</td>\n","      <td>NaN</td>\n","      <td>Intel</td>\n","      <td>NaN</td>\n","      <td>us</td>\n","    </tr>\n","    <tr>\n","      <th>1600034</th>\n","      <td>B073XGST2Q</td>\n","      <td>Intel Xeon Gold 5118 Tray Processor</td>\n","      <td>Processors</td>\n","      <td>Processors</td>\n","      <td>Intel</td>\n","      <td>gold</td>\n","      <td>us</td>\n","    </tr>\n","    <tr>\n","      <th>1600035</th>\n","      <td>B0793BQS3R</td>\n","      <td>Intel Pentium Gold G5400 Desktop Processor 2 C...</td>\n","      <td>INTEL BX80684G5400</td>\n","      <td>BX80684G5400\\nINTEL</td>\n","      <td>Intel</td>\n","      <td>Gold</td>\n","      <td>us</td>\n","    </tr>\n","    <tr>\n","      <th>1600036</th>\n","      <td>B07R6XPQYB</td>\n","      <td>Intel Xeon Gold 5218 Tray Processor 16 Core 2....</td>\n","      <td>Intel Xeon Gold processors offer high performa...</td>\n","      <td>Intel Xeon Gold processors offer high performa...</td>\n","      <td>Intel OEM Tray Processors</td>\n","      <td>NaN</td>\n","      <td>us</td>\n","    </tr>\n","    <tr>\n","      <th>1600037</th>\n","      <td>B07RC9FD97</td>\n","      <td>Intel Xeon Gold 5222 Tray Processor 4 Core 3.8...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Intel OEM Tray Processors</td>\n","      <td>NaN</td>\n","      <td>us</td>\n","    </tr>\n","    <tr>\n","      <th>1600038</th>\n","      <td>B07SBKXDNS</td>\n","      <td>Intel Pentium Gold G5420 Desktop Processor 2 C...</td>\n","      <td>NaN</td>\n","      <td>2 Cores /4 Threads\\n3.8 GHz\\nCompatible with I...</td>\n","      <td>Intel</td>\n","      <td>NaN</td>\n","      <td>us</td>\n","    </tr>\n","    <tr>\n","      <th>1600039</th>\n","      <td>B07SLSGBJP</td>\n","      <td>Intel Pentium Gold G5420 Dual Core 3.8GHz LGA ...</td>\n","      <td>Intel Pentium Gold G5420 Processor (4MB Cache,...</td>\n","      <td>3.8GHz processor speed\\nDual Core desktop proc...</td>\n","      <td>Intel</td>\n","      <td>NaN</td>\n","      <td>us</td>\n","    </tr>\n","    <tr>\n","      <th>1600040</th>\n","      <td>B07SZ9TPW7</td>\n","      <td>Intel Xeon Gold 6254 Processor 18 Core 3.10GHZ...</td>\n","      <td>Intel Xeon Gold 6254 Processor | 18-Core, 36 T...</td>\n","      <td>Intel Xeon Gold 6254 Processor\\n18-Core, 36 Th...</td>\n","      <td>Intel OEM Tray Processors</td>\n","      <td>NaN</td>\n","      <td>us</td>\n","    </tr>\n","    <tr>\n","      <th>1600041</th>\n","      <td>B0857MBSD4</td>\n","      <td>INTEL INTEL XEON Gold 6246R Processor (35.75M ...</td>\n","      <td>INTEL reg; XEON reg; GOLD PROCESSORS With supp...</td>\n","      <td>W126171725</td>\n","      <td>Intel</td>\n","      <td>NaN</td>\n","      <td>us</td>\n","    </tr>\n","    <tr>\n","      <th>1600042</th>\n","      <td>B0858CVWK4</td>\n","      <td>INTEL INTEL XEON Gold 6240R Processor (35.75M ...</td>\n","      <td>INTEL reg; XEON reg; GOLD PROCESSORS With supp...</td>\n","      <td>W126171723</td>\n","      <td>Intel</td>\n","      <td>NaN</td>\n","      <td>us</td>\n","    </tr>\n","    <tr>\n","      <th>1600043</th>\n","      <td>B086K4V42L</td>\n","      <td>Intel XEON Gold 6226R Processor 16 CORE 2.90GH...</td>\n","      <td>INTEL XEON GOLD PROCESSORS With support for th...</td>\n","      <td>INTEL XEON GOLD PROCESSORS With support for th...</td>\n","      <td>Intel OEM Tray Processors</td>\n","      <td>NaN</td>\n","      <td>us</td>\n","    </tr>\n","    <tr>\n","      <th>1600044</th>\n","      <td>B086MGYKXM</td>\n","      <td>Intel Pentium Gold G-6500 Desktop Processor 2 ...</td>\n","      <td>NaN</td>\n","      <td>2 Cores / 4 Threads\\nSocket Type LGA 1200\\nCom...</td>\n","      <td>Intel</td>\n","      <td>NaN</td>\n","      <td>us</td>\n","    </tr>\n","    <tr>\n","      <th>1600045</th>\n","      <td>B086MHSH2Z</td>\n","      <td>Intel Pentium Gold G-6400 Desktop Processor 2 ...</td>\n","      <td>NaN</td>\n","      <td>2 Cores / 4 Threads\\nSocket Type LGA 1200\\nCom...</td>\n","      <td>Intel</td>\n","      <td>NaN</td>\n","      <td>us</td>\n","    </tr>\n","    <tr>\n","      <th>1600046</th>\n","      <td>B08M9BS284</td>\n","      <td>Intel Xeon Gold 6140 SR3AX 18-Core 2.3GHz 24.7...</td>\n","      <td>Intel Xeon Gold 6140 SR3AX 18-Core 2.3GHz 24.7...</td>\n","      <td>18 Cores, 36 Cores in Hyperthreading mode\\n2.3...</td>\n","      <td>Intel</td>\n","      <td>NaN</td>\n","      <td>us</td>\n","    </tr>\n","    <tr>\n","      <th>1600047</th>\n","      <td>B08ML8J37K</td>\n","      <td>Intel Xeon Gold 6130 SR3B9 16-Core 2.1GHz 22MB...</td>\n","      <td>Intel Xeon Gold 6130 SR3B9 16-Core 2.1GHz 22.0...</td>\n","      <td>16 Cores, 32 Cores in Hyperthreading mode\\n2.1...</td>\n","      <td>Intel</td>\n","      <td>NaN</td>\n","      <td>us</td>\n","    </tr>\n","    <tr>\n","      <th>1600048</th>\n","      <td>B091TXJN41</td>\n","      <td>Intel Pentium Gold G6405 4.1GHz 4MB Desktop Pr...</td>\n","      <td>Intel® Pentium® Processors Discover new comput...</td>\n","      <td>Processor Manufacturer: Intel\\nProcessor Core:...</td>\n","      <td>Intel</td>\n","      <td>NaN</td>\n","      <td>us</td>\n","    </tr>\n","    <tr>\n","      <th>1600049</th>\n","      <td>B0019K9OWA</td>\n","      <td>iDesign Axis Over the Cabinet 2-Tier Kitchen S...</td>\n","      <td>NaN</td>\n","      <td>OVER THE CABINET STORAGE: Wire over the cabine...</td>\n","      <td>iDesign</td>\n","      <td>Two Tier</td>\n","      <td>us</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ad9d6df6-5366-4000-8cdf-ef5b2adf5d4f')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-ad9d6df6-5366-4000-8cdf-ef5b2adf5d4f button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-ad9d6df6-5366-4000-8cdf-ef5b2adf5d4f');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["         product_id                                      product_title  \\\n","1600000  B07RK154DV  Stemless Wine Tumbler with Lid and Straw, Bast...   \n","1600001  B07T3SLJQ7  PURECUP 12 oz Wine Tumbler With Spill-proof Li...   \n","1600002  B07TF6JXSG  Comfook Glass Bulk Set Wine Cups Glasses with ...   \n","1600003  B07VH1XG7J  Deitybless 6 Pack 12 oz Stainless Steel Wine T...   \n","1600004  B0822R1N1K  Vacuum Insulated Wine Tumbler with Sliding Lid...   \n","1600005  B082SC54BP  MUCHENGHY 12 oz Wine Glass Tumbler Bulk with L...   \n","1600006  B01M71BZD9  Yedi 9-in-1 Total Package Instant Programmable...   \n","1600007  B01NBKTPTS  Instant Pot Duo Plus 6 Quart 9-in-1 Electric P...   \n","1600008  B0777XQ4S8  Instant Pot Smart Wifi 6 Quart Multi-use Elect...   \n","1600009  B077T9YGRM  Instant Pot Max 6 Quart Multi-use Electric Pre...   \n","1600010  B07LDJD3X5  Instant Pot 8 QT Viva 9-in-1 Multi-Use Program...   \n","1600011  B07R4TMNXK  prepAmeal 6QT 8 IN 1 Pressure Cooker MultiUse ...   \n","1600012  B07VT23JDM  Instant Pot Duo Crisp 11-in-1 Electric Pressur...   \n","1600013  B07WLJN9YZ              Nuwave Nutri-Pot 13Qt Pressure Cooker   \n","1600014  B087NSG5XB  The Pioneer Woman Instant Pot DUO60 6-Quart Fr...   \n","1600015  B08SRS4TW2  Instant Pot Ultra 10-in-1 Electric Pressure Co...   \n","1600016  B091CYX72J  Tezam Reusable Air Fryer Liners – 7.5 Inch Squ...   \n","1600017  0887276407  Integrated Chinese Level 1 Part 1 Workbook: Si...   \n","1600018  0887276938  Reading Into a New China: Integrated Skills fo...   \n","1600019  0976998130  Japanese From Zero! 3: Proven Techniques to Le...   \n","1600020  0989654524  Korean From Zero! 1: Master the Korean Languag...   \n","1600021  1091714746  First Chinese Characters Book Easy Practice Wr...   \n","1600022  1622911318  Integrated Chinese 4th Edition, Volume 1 Workb...   \n","1600023  1622911350  Integrated Chinese 4th Edition, Volume 1 Textb...   \n","1600024  1622911369  Integrated Chinese 4th Edition, Volume 1 Workb...   \n","1600025  1622911377  Integrated Chinese 4th Edition, Volume 1 Chara...   \n","1600026  1622911415  Integrated Chinese 2 Textbook Simplified (Chin...   \n","1600027  1622911512  Integrated Chinese Textbook Vol 4 (English and...   \n","1600028  1622911563  Integrated Chinese Volume 3 Textbook, 4th edit...   \n","1600029  1622911571  Integrated Chinese 3 Workbook, 4th edition (En...   \n","1600030  478901441X  Genki: An Integrated Course in Elementary Japa...   \n","1600031  4883196070  Minna no Nihongo 2nd Edition Beginner vol.1 Bu...   \n","1600032  B07ZH25X3N  Advanced Hematology in Integrated Cardiovascul...   \n","1600033  B073XGDFY9                Intel Xeon Gold 5120 Tray Processor   \n","1600034  B073XGST2Q                Intel Xeon Gold 5118 Tray Processor   \n","1600035  B0793BQS3R  Intel Pentium Gold G5400 Desktop Processor 2 C...   \n","1600036  B07R6XPQYB  Intel Xeon Gold 5218 Tray Processor 16 Core 2....   \n","1600037  B07RC9FD97  Intel Xeon Gold 5222 Tray Processor 4 Core 3.8...   \n","1600038  B07SBKXDNS  Intel Pentium Gold G5420 Desktop Processor 2 C...   \n","1600039  B07SLSGBJP  Intel Pentium Gold G5420 Dual Core 3.8GHz LGA ...   \n","1600040  B07SZ9TPW7  Intel Xeon Gold 6254 Processor 18 Core 3.10GHZ...   \n","1600041  B0857MBSD4  INTEL INTEL XEON Gold 6246R Processor (35.75M ...   \n","1600042  B0858CVWK4  INTEL INTEL XEON Gold 6240R Processor (35.75M ...   \n","1600043  B086K4V42L  Intel XEON Gold 6226R Processor 16 CORE 2.90GH...   \n","1600044  B086MGYKXM  Intel Pentium Gold G-6500 Desktop Processor 2 ...   \n","1600045  B086MHSH2Z  Intel Pentium Gold G-6400 Desktop Processor 2 ...   \n","1600046  B08M9BS284  Intel Xeon Gold 6140 SR3AX 18-Core 2.3GHz 24.7...   \n","1600047  B08ML8J37K  Intel Xeon Gold 6130 SR3B9 16-Core 2.1GHz 22MB...   \n","1600048  B091TXJN41  Intel Pentium Gold G6405 4.1GHz 4MB Desktop Pr...   \n","1600049  B0019K9OWA  iDesign Axis Over the Cabinet 2-Tier Kitchen S...   \n","\n","                                       product_description  \\\n","1600000  <b>Bastwe 4 Pack 12oz Vacuum Insulated Wine Tu...   \n","1600001  <b>Specification:</b><br>*Designs: Stainless W...   \n","1600002                                                NaN   \n","1600003  Deitybless pack wine tumbler cup with lids 12 ...   \n","1600004  <b>LEVIN Vacuum Insulated Wine Tumbler with Sl...   \n","1600005  <p>Mucheng Vacuum Insulated Wine Tumbler with ...   \n","1600006                                                NaN   \n","1600007                                                NaN   \n","1600008                                                NaN   \n","1600009                                                NaN   \n","1600010              Instant Pot Viva 9 in 1 / New Product   \n","1600011  <b>There Pressure Settings</b><br> For fast an...   \n","1600012                                                NaN   \n","1600013  Make a hearty beef stew in this Nutri-Pot digi...   \n","1600014                                                 SA   \n","1600015                                                NaN   \n","1600016  <b>Features:</b><br><p> 1) 100% Reusable, Non-...   \n","1600017                                                NaN   \n","1600018                                                NaN   \n","1600019                                                NaN   \n","1600020                                                NaN   \n","1600021                                                NaN   \n","1600022                                                NaN   \n","1600023                                                NaN   \n","1600024                                                NaN   \n","1600025                                                NaN   \n","1600026                                                NaN   \n","1600027                                                NaN   \n","1600028                                                NaN   \n","1600029                                                NaN   \n","1600030                                                NaN   \n","1600031                                                NaN   \n","1600032  <p><i>Advanced Hematology in Integrative Cardi...   \n","1600033  Intel 2.2GHz Xeon Gold 5120 14-core FCLGA3647 ...   \n","1600034                                         Processors   \n","1600035                                 INTEL BX80684G5400   \n","1600036  Intel Xeon Gold processors offer high performa...   \n","1600037                                                NaN   \n","1600038                                                NaN   \n","1600039  Intel Pentium Gold G5420 Processor (4MB Cache,...   \n","1600040  Intel Xeon Gold 6254 Processor | 18-Core, 36 T...   \n","1600041  INTEL reg; XEON reg; GOLD PROCESSORS With supp...   \n","1600042  INTEL reg; XEON reg; GOLD PROCESSORS With supp...   \n","1600043  INTEL XEON GOLD PROCESSORS With support for th...   \n","1600044                                                NaN   \n","1600045                                                NaN   \n","1600046  Intel Xeon Gold 6140 SR3AX 18-Core 2.3GHz 24.7...   \n","1600047  Intel Xeon Gold 6130 SR3B9 16-Core 2.1GHz 22.0...   \n","1600048  Intel® Pentium® Processors Discover new comput...   \n","1600049                                                NaN   \n","\n","                                      product_bullet_point  \\\n","1600000  💥 Food Grade Stainless Steel: The wine glass i...   \n","1600001  12OZ insulated stainless stell wine glasses wi...   \n","1600002  For Any Occasion: 12 oz glass is in a beautifu...   \n","1600003  【HIGHT QUALITY】The wine tumbler is made of goo...   \n","1600004  【Preserve the Most Wanted Temp & Flavour】 Adop...   \n","1600005  【GIVE AS A PRESENT TO COMMEMORATE!】 It's strik...   \n","1600006  OPRAH’S FAVORITE THINGS: The Yedi 9-in-1 Total...   \n","1600007  SIMPLE, STRESS-FREE VENTING with an intuitive ...   \n","1600008  Cooks fast and saves time: The Instant Pot Sma...   \n","1600009  Sustained 15psi, not only cooks food faster, y...   \n","1600010                       INSTANT POT\\nPressure Cooker   \n","1600011  8-IN-1 Multi-Functional Pot : 1 Electric Press...   \n","1600012  11-IN-1 FUNCTIONALITY: Air fry, roast, bake, d...   \n","1600013  EVERYTHING YOU NEED- Your 13Q NutriPot Digital...   \n","1600014                                                NaN   \n","1600015  Product 1: For large families, 6+ people. Item...   \n","1600016  NEW RELEASE! SAVE MONEY ON PARCHMENT PAPER or ...   \n","1600017                        Used Book in Good Condition   \n","1600018                        Used Book in Good Condition   \n","1600019                        Used Book in Good Condition   \n","1600020                               Yesjapan Corporation   \n","1600021                                                NaN   \n","1600022                                                NaN   \n","1600023                                                NaN   \n","1600024                                                NaN   \n","1600025                                                NaN   \n","1600026                                                NaN   \n","1600027                                                NaN   \n","1600028                                                NaN   \n","1600029                                                NaN   \n","1600030  ◆Second edition of the most highly regarded te...   \n","1600031                                                NaN   \n","1600032                                                NaN   \n","1600033                                                NaN   \n","1600034                                         Processors   \n","1600035                                BX80684G5400\\nINTEL   \n","1600036  Intel Xeon Gold processors offer high performa...   \n","1600037                                                NaN   \n","1600038  2 Cores /4 Threads\\n3.8 GHz\\nCompatible with I...   \n","1600039  3.8GHz processor speed\\nDual Core desktop proc...   \n","1600040  Intel Xeon Gold 6254 Processor\\n18-Core, 36 Th...   \n","1600041                                         W126171725   \n","1600042                                         W126171723   \n","1600043  INTEL XEON GOLD PROCESSORS With support for th...   \n","1600044  2 Cores / 4 Threads\\nSocket Type LGA 1200\\nCom...   \n","1600045  2 Cores / 4 Threads\\nSocket Type LGA 1200\\nCom...   \n","1600046  18 Cores, 36 Cores in Hyperthreading mode\\n2.3...   \n","1600047  16 Cores, 32 Cores in Hyperthreading mode\\n2.1...   \n","1600048  Processor Manufacturer: Intel\\nProcessor Core:...   \n","1600049  OVER THE CABINET STORAGE: Wire over the cabine...   \n","\n","                     product_brand                   product_color_name  \\\n","1600000                     Bastwe                                Black   \n","1600001                    PURECUP                            Aqua Blue   \n","1600002                    Comfook                         Multicolor B   \n","1600003                 Deitybless  Assorted Colors_6 pack(with straws)   \n","1600004                      LEVIN                                Black   \n","1600005                  MUCHENGHY                            Rose Gold   \n","1600006             YEDI HOUSEWARE                      Stainless Steel   \n","1600007                Instant Pot                Stainless Steel/Black   \n","1600008                Instant Pot                               Silver   \n","1600009                Instant Pot                               Silver   \n","1600010                Instant Pot                                  NaN   \n","1600011                  prepAmeal                              6 Quart   \n","1600012                Instant Pot                Black/Stainless Steel   \n","1600013                     NuWave                                  NaN   \n","1600014                  BATEMEN W                     11.28-WDBGM-1754   \n","1600015                Instant Pot                                  NaN   \n","1600016                      Tezam                                  NaN   \n","1600017          Brand: Cheng Tsui                                  NaN   \n","1600018          Brand: Cheng Tsui                                  NaN   \n","1600019       YesJapan Corporation                                  NaN   \n","1600020       YesJapan Corporation                                  NaN   \n","1600021    Independently Published                                  NaN   \n","1600022                        NaN                                  NaN   \n","1600023                        NaN                                  NaN   \n","1600024                        NaN                                  NaN   \n","1600025                        NaN                                  NaN   \n","1600026                        NaN                                  NaN   \n","1600027                        NaN                                  NaN   \n","1600028                        NaN                                  NaN   \n","1600029                        NaN                                  NaN   \n","1600030                Japan Times                                  NaN   \n","1600031             3A CORPORATION                                  NaN   \n","1600032                        NaN                                  NaN   \n","1600033                      Intel                                  NaN   \n","1600034                      Intel                                 gold   \n","1600035                      Intel                                 Gold   \n","1600036  Intel OEM Tray Processors                                  NaN   \n","1600037  Intel OEM Tray Processors                                  NaN   \n","1600038                      Intel                                  NaN   \n","1600039                      Intel                                  NaN   \n","1600040  Intel OEM Tray Processors                                  NaN   \n","1600041                      Intel                                  NaN   \n","1600042                      Intel                                  NaN   \n","1600043  Intel OEM Tray Processors                                  NaN   \n","1600044                      Intel                                  NaN   \n","1600045                      Intel                                  NaN   \n","1600046                      Intel                                  NaN   \n","1600047                      Intel                                  NaN   \n","1600048                      Intel                                  NaN   \n","1600049                    iDesign                             Two Tier   \n","\n","        product_locale  \n","1600000             us  \n","1600001             us  \n","1600002             us  \n","1600003             us  \n","1600004             us  \n","1600005             us  \n","1600006             us  \n","1600007             us  \n","1600008             us  \n","1600009             us  \n","1600010             us  \n","1600011             us  \n","1600012             us  \n","1600013             us  \n","1600014             us  \n","1600015             us  \n","1600016             us  \n","1600017             us  \n","1600018             us  \n","1600019             us  \n","1600020             us  \n","1600021             us  \n","1600022             us  \n","1600023             us  \n","1600024             us  \n","1600025             us  \n","1600026             us  \n","1600027             us  \n","1600028             us  \n","1600029             us  \n","1600030             us  \n","1600031             us  \n","1600032             us  \n","1600033             us  \n","1600034             us  \n","1600035             us  \n","1600036             us  \n","1600037             us  \n","1600038             us  \n","1600039             us  \n","1600040             us  \n","1600041             us  \n","1600042             us  \n","1600043             us  \n","1600044             us  \n","1600045             us  \n","1600046             us  \n","1600047             us  \n","1600048             us  \n","1600049             us  "]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["df[1600000:1600050]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"44qa8hxykZEG"},"outputs":[],"source":["class Transformer(tf.keras.Model):\n","  def __init__(self,transformer):\n","    super(Transformer,self).__init__()\n","    self.transformer=transformer\n","    \n","  def compile(self,loss_fn,optimizer):\n","    super(Transformer,self).compile()\n","    self.optimizer=optimizer\n","    self.loss_fn=loss_fn\n","    self.loss_metric=tf.keras.metrics.Mean(name='loss')\n","    \n","  @property\n","  def metrics(self):\n","    return [self.loss_metric,]\n","\n","  def train_step(self,x_y):\n","    inputs,target=x_y\n","    encoder_input=inputs['input_1']\n","    shifted_target=inputs['input_2']\n","\n","    with tf.GradientTape() as recorder:\n","\n","      output,_=self.transformer([encoder_input,shifted_target])\n","      loss=self.loss_fn(target,output)\n","      \n","    partial_derivatives = recorder.gradient(loss,self.transformer.trainable_weights)\n","    self.optimizer.apply_gradients(zip(partial_derivatives, self.transformer.trainable_weights))\n","\n","    self.loss_metric.update_state(loss)\n","    \n","    return {'loss':self.loss_metric.result()}"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["RBHsJDpiYDs7","QaDKmgJgklY_"],"provenance":[{"file_id":"1awyXVSqfhBLykr43uWDESu4CTn7VmqOl","timestamp":1673806928577},{"file_id":"1Azfk7PQQ3FoBJWSxSkqxquML6LYpZCYS","timestamp":1662195319517},{"file_id":"1wOi9I4Ett5qIJ3eldJ3bTPRmUjk3X5hd","timestamp":1662058828939}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
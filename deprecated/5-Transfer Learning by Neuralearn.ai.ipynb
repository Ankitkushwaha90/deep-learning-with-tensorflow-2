{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8e0693",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers. imoprt Dense, Conv2D, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy,SparseCategoricalAccuracy,SparseTopCategoricalAccuracy\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy, SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "import time\n",
    "import pandas as pd\n",
    "from shutil import copy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853c175f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_directory = '...'\n",
    "validation_directory = '...'\n",
    "world_files = '...'\n",
    "dst = '...'\n",
    "INPUT_DIM = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73810aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_directory,\n",
    "    image_size = (INPUT_DIM, INPUT_DIM),\n",
    "    batch_size = 4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06744b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    validation_directory,\n",
    "    image_size = (INPUT_DIM, INPUT_DIM),\n",
    "    batch_size = 4096)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb49aff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db30b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model=tf.keras.applications.VGG16(input_shape=(224,224,3),\n",
    "                                      include_top=True,\n",
    "                                      weights='imagenet')\n",
    "model=base_model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c8b8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_maps=[layer.output for layer in model.layers[:5]]\n",
    "activation_model=Model(inputs=model.input,outputs=feature_maps)\n",
    "activation_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc296c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test-image='...'\n",
    "image=tf.keras.preprocessing.image.load_img(test_imag,color_mode='rgb',target_size=(224,224))\n",
    "image=tf.convert_to_tensor(tf.keras.preprocessing.image.img_to_array(image))/255.\n",
    "activations=activation_model.predict(tf.expand_dims(image,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f4f585",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    print(activations[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e7bf31",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size=5\n",
    "num_of_channels=4\n",
    "for i in range(1,len(activations)):\n",
    "    print(\"Feature map number ---> \",i)\n",
    "    axes=[]\n",
    "    fig=plt.figure()\n",
    "    fig.set_figheight(image_size)\n",
    "    fig.set_figwidth(image_size)\n",
    "    \n",
    "    for channel in range(num_of_channels):\n",
    "        axes.append(fig.add_subplot(int(np.sqrt(num_of_channels)),int(np.sqrt(num_of_channels)),channel+1))\n",
    "        subplot_title=(\"Channel\"+str(channel))\n",
    "        axes[-1].set_title(subplot_title)\n",
    "        plt.imshow(activations[i][0,:,:,channel])\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f59abd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71779934",
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone=tf.keras.applications.MobileNetV2(input_shape=(224,224,3),\n",
    "                                      include_top=True,\n",
    "                                      weights='imagenet')\n",
    "\n",
    "backbone.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7abdf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8dac7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs=Input(shape=(64,64,3))\n",
    "\n",
    "x=tf.keras.preprocesssing.Rescaling(1/255.)(inputs)\n",
    "x=backbone(inputs,training=False)\n",
    "x=GlobalAveragePooling2D(x)\n",
    "x=Dense(1000)(x)\n",
    "outputs=Dense(200,activation='softmax')(x)\n",
    "model=Model(inputs,outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd905df",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5734c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=Adam(lr=1e-3,\n",
    "    loss=SparseCategoricalCrossentropy(),\n",
    "    metrics=[SparseCategoricalAccuracy(),SparseCategoricalAccuracy(k=5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7f3fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 15\n",
    "history = model.fit(train_dataset, validation_data=val_dataset, epochs=NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bf298a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(history.history['loss'][0:60])\n",
    "plt.plot(history.history['val_loss'][0:60])\n",
    "\n",
    "plt.title('model_losss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caedae5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92ffcaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac73be3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce89084",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

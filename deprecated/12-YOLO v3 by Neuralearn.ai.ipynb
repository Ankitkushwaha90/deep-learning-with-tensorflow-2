{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e105f643",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf### models\n",
    "import numpy as np### math computations\n",
    "import matplotlib.pyplot as plt### plotting bar chart\n",
    "import sklearn### machine learning library\n",
    "import cv2## image processing\n",
    "from sklearn.metrics import confusion_matrix, roc_curve### metrics\n",
    "import seaborn as sns### visualizations\n",
    "import datetime\n",
    "import pathlib\n",
    "import io\n",
    "import json\n",
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "from google.colab import files\n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras.layers import (GlobalAveragePooling2D, Activation, MaxPooling2D, Add, Conv2D, MaxPool2D, Dense,\n",
    "                                     Flatten, InputLayer, BatchNormalization, Input, Embedding, Permute,\n",
    "                                     Dropout, RandomFlip, RandomRotation, LayerNormalization, MultiHeadAttention,\n",
    "                                     RandomContrast, Rescaling, Resizing, Reshape,LeakyReLU)\n",
    "from tensorflow.keras.losses import BinaryCrossentropy,CategoricalCrossentropy, SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import Accuracy,TopKCategoricalAccuracy, CategoricalAccuracy, SparseCategoricalAccuracy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import (Callback, CSVLogger, EarlyStopping, LearningRateScheduler,\n",
    "                                        ModelCheckpoint, ReduceLROnPlateau)\n",
    "from tensorflow.keras.regularizers import L2, L1\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "from tensorflow.train import BytesList, FloatList, Int64List\n",
    "from tensorflow.train import Example, Features, Feature\n",
    "from google.colab import drive\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451711be",
   "metadata": {},
   "source": [
    "<H1>DATA PREPARATION</H1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c55e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Utils():\n",
    "    def __init__(self, split_size, num_boxes, classes):\n",
    "        self.split_size = split_size\n",
    "        self.num_boxes = num_boxes\n",
    "        self.classes = classes\n",
    "        \n",
    "    def preprocess_xml(self, filename,m_a_p=False):\n",
    "        tree = ET.parse(filename)\n",
    "        root = tree.getroot()\n",
    "        bounding_boxes = []\n",
    "\n",
    "        size_tree = root.find('size')\n",
    "        height = float(size_tree.find('height').text)\n",
    "        width = float(size_tree.find('width').text)\n",
    "\n",
    "        for object_tree in root.findall('object'):\n",
    "            for bounding_box in object_tree.iter('bndbox'):\n",
    "\n",
    "                xmin = (float(bounding_box.find('xmin').text)/width)\n",
    "                ymin = (float(bounding_box.find('ymin').text)/height)\n",
    "                xmax = (float(bounding_box.find('xmax').text)/width)\n",
    "                ymax = (float(bounding_box.find('ymax').text)/height)\n",
    "                if m_a_p:\n",
    "                    xmin=int(xmin*width)\n",
    "                    ymin=int(ymin*height)\n",
    "                    xmax=int(xmax*width)\n",
    "                    ymax=int(ymax*height)\n",
    "                break\n",
    "            class_name = object_tree.find('name').text\n",
    "            bounding_box = [xmin,ymin,xmax,ymax,class_name]\n",
    "            bounding_boxes.append(bounding_box)\n",
    "        if m_a_p:\n",
    "            return bounding_boxes,(height,width)\n",
    "    return bounding_boxes\n",
    "\n",
    "    def midpoint(self, x,y):\n",
    "        return (x+y)/2\n",
    "    def get_pos(self,classes, classe):\n",
    "        for c in range(len(classes)):\n",
    "            if(classes[c]==classe):\n",
    "                return c\n",
    "    def generate_pre_output(self,bounding_boxes,image_shape):\n",
    "        height,width=image_shape\n",
    "        bbox=[]\n",
    "        for box in bounding_boxes:\n",
    "            x_min,y_min,x_max,y_max,obj=box[0],box[1],box[2],box[3],box[4]\n",
    "            bbox.append([int(x_min/width*224),int(y_min/height*224),int(x_max/width*224),int(y_max/height*224),obj])\n",
    "        return bbox\n",
    "    def bounding_box_to_output(self,box,offset,anchor):\n",
    "        output=[0,0,0,0,1]\n",
    "        output[0]=tf.math.log((box[0]-offset[0])/(1+offset[0]-box[0]))\n",
    "        output[1]=tf.math.log((box[1]-offset[1])/(1+offset[1]-box[1]))\n",
    "        \n",
    "        output[2]=tf.math.log(box[2]/anchor[0])\n",
    "        output[3]=tf.math.log(box[3]/anchor[1])\n",
    "        return np.array(output)\n",
    "    \n",
    "    \n",
    "    def generate_output(self, bounding_boxes):\n",
    "        anchor_boxes=[[1.3,1.3],[2.3,1.3],[1.3,2.3]]\n",
    "        output_label = np.zeros((self.split_size, self.split_size, len(anchor_boxes), len(self.classes)+(5*self.num_boxes)))\n",
    "\n",
    "        for box in bounding_boxes:\n",
    "            for a in range(len(anchor_boxes)):\n",
    "\n",
    "                x_min, y_min, x_max, y_max = box[0], box[1], box[2], box[3]\n",
    "\n",
    "                x_centre = self.midpoint(x_min, x_max)\n",
    "                y_centre = self.midpoint(y_min, y_max)\n",
    "\n",
    "                x_width = (x_max - x_min)*self.split_size\n",
    "                y_height = (y_max - y_min)*self.split_size\n",
    "\n",
    "                b_x_centre_cell = (x_centre*self.split_size)\n",
    "                b_y_centre_cell = (y_centre*self.split_size)\n",
    "\n",
    "                i = int(b_x_centre_cell)\n",
    "                j = int(b_y_centre_cell)\n",
    "                \n",
    "                offset = [i,j]\n",
    "                b = [b_x_centre_cell,b_y_centre_cell,x_width,y_height]\n",
    "                width,height=box[5],box[6]\n",
    "                \n",
    "                b_x_min=((b_x_centre_cell-(anchor_boxes[a][0]/2))/self.split_size)*width\n",
    "                if b_x_min<0:\n",
    "                    b_x_min=0.\n",
    "                b_y_min=((b_y_centre_cell-(anchor_boxes[a][1]/2))/self.split_size)*height\n",
    "                if b_y_min<0:\n",
    "                    b_y_min=0.\n",
    "                \n",
    "                \n",
    "                b_x_max=((b_x_centre_cell+(anchor_boxes[a][0]/2))/self.split_size)*width\n",
    "                b_y_max=((b_y_centre_cell+(anchor_boxes[a][1]/2))/self.split_size)*height\n",
    "                \n",
    "                x_centre_cell = (x_centre*self.split_size)-i\n",
    "                y_centre_cell = (y_centre*self.split_size)-j\n",
    "\n",
    "                bbox.append(self.bounding_box_to_output(b,offset,anchor_boxes[a]))\n",
    "                box_iou.append(self.iou([x_min*width,y_min*height,x_max*width,y_max*height],[b_x_min,b_y_min,b_x_max,b_y_max]))\n",
    "            \n",
    "            highest_a = tf.argmax(tf.constant(box_iou)).numpy()\n",
    "            output_label[i,j,highest_a,22:27] = self.bounding_box_to_output(b,offset,anchor_boxes[highest_a])\n",
    "            output_label[i,j,highest_a,self.get_pos(self.classes, box[4])] = 1.\n",
    "            \n",
    "        return output_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d2b110",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image='...'\n",
    "image = tf.keras.preprocessing.image.load_img(\n",
    "    test_image,color_mode='rgb',target_size=(224,224)\n",
    ")\n",
    "classes = ['background','aeroplane','bicycle','bird','boat','bottle','bus','car','cat',\n",
    "           'chair','cow','diningtable','dog','horse','motorbike','person','pottedplant',\n",
    "           'sheep','sofa','train','tvmonitor','book']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96473d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__ (self, train_images, train_maps, split_size, num_boxes, classes, batch_size, shuffle = False):\n",
    "\n",
    "        self.train_images = train_images\n",
    "        self.train_maps = train_maps\n",
    "        self.train_image_list = os.listdir(self.train_images)\n",
    "        self.train_map_list = os.listdir(self.train_maps)\n",
    "        self.split_size = split_size\n",
    "        self.num_boxes = num_boxes\n",
    "        self.classes = classes\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.train_image_list)/self.batch_size))\n",
    "  \n",
    "    def __getitem__(self, idx):\n",
    "        x,y_1,y_2 = self.__data_generation(idx)\n",
    "        return np.array(x), [y_1,y_2]\n",
    "  \n",
    "    def __data_generation(self, idx):\n",
    "        x = np.empty((self.batch_size, 224,224,3))\n",
    "        y_1 = np.zeros((self.batch_size, self.split_size, self.split_size,3,27))\n",
    "        y_2 = np.zeros((self.batch_size, self.split_size*4, self.split_size*4,3,27))\n",
    "\n",
    "        for i,j in enumerate(list(range(idx*self.batch_size, (idx+1)*self.batch_size))):\n",
    "            image = tf.keras.preprocessing.image.load_img(self.train_images + self.train_image_list[j],\n",
    "                                                        color_mode ='rgb', target_size = (224,224))\n",
    "            \n",
    "            x[i] = tf.keras.preprocessing.image.img_to_array(image)\n",
    "            utils = Utils(self.split_size,self.num_boxes,self.classes)\n",
    "            bounding_boxes = utils.preprocess_xml(self.train_maps+self.train_map_list[j])\n",
    "            y_1[i] = utils.generate_output(bounding_boxes)\n",
    "\n",
    "            utils = Utils(self.split_size*4,self.num_boxes,self.classes)\n",
    "            bounding_boxes = utils.preprocess_xml(self.train_maps+self.train_map_list[j])\n",
    "            y_1[i] = utils.generate_output(bounding_boxes)\n",
    "\n",
    "            \n",
    "        return x,y_1,y_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b13e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR=1e-3\n",
    "BATCH_SIZE=32\n",
    "EPOCH=100\n",
    "train_images='...'\n",
    "train_maps='...'\n",
    "val_images='...'\n",
    "val_maps='...'\n",
    "split_size=7\n",
    "num_boxes=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decf38a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = DataGenerator(train_images, train_maps, split_size, num_boxes, classes, batch_size=BATCH_SIZE)\n",
    "val_gen = DataGenerator(val_images, val_maps, split_size, num_boxes, classes, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b789875",
   "metadata": {},
   "source": [
    "<H1>MODELING</H1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60497989",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_base_model():\n",
    "    base_model = tf.keras.applications.mobilenet_v2.MobileNetV2(\n",
    "        weights='imagenet',\n",
    "        input_shape=(INPUT_DIM,INPUT_DIM,3),\n",
    "        include_top=False,)\n",
    "    base_model.trainable=False\n",
    "    block_6_output,out_relu=[base_model.get_layer(layer_name).output for layer_name in [\"block_6_expand_relu\",\"out_relu\"]]\n",
    "    \n",
    "    return Model(\n",
    "        inputs=[base_model.inputs],outputs=[out_relu,block_6_output]\n",
    "    )\n",
    "\n",
    "get_base_model().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8f92a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class head(tf.keras.layers.Layer):\n",
    "    def __init__(self,OUTPUT_DIM,OUTPUT_SHAPE,NUM_FILTERS):\n",
    "        super(Head,self).__init__()\n",
    "        \n",
    "        self.conv_1=Conv2D(NUM_FILTERS,(3,3),activation='relu',kernel_initializer=RandomNormal(0.01))\n",
    "        self.conv_2=Conv2D(NUM_FILTERS,(3,3),activation='relu',kernel_initializer=RandomNormal(0.01))\n",
    "        self.conv_3=Conv2D(OUTPUT_DIM,(3,3),activation='relu',kernel_initializer=RandomNormal(0.01))\n",
    "        self.norm_1=LayerNormalization()\n",
    "        \n",
    "        self.flatten=Flatten()\n",
    "        self.reshape=Reshape(OUTPUT_SHAPE)\n",
    "    def call(self,images,training=False):\n",
    "        x=self.conv_1(images)\n",
    "        x=self.conv_2(x)\n",
    "        x=self.conv_3(x)\n",
    "        x=self.norm_1(x)\n",
    "        x=self.flatten(x)\n",
    "        x=self.reshape(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5df3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = 224\n",
    "NUM_FILTERS = 16\n",
    "\n",
    "s = 7\n",
    "c = len(classes)\n",
    "b = 1\n",
    "\n",
    "OUTPUT_DIM  = s*s*3*(c+5*b)\n",
    "OUTPUT_SHAPE = (s,s,3,c+5*b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed044d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape = (INPUT_DIM, INPUT_DIM, 3))\n",
    "out_relu,block_6_output=get_base_model()(inputs)\n",
    "head_7=Head(OUTPUT_DIM,OUTPUT_SHAPE,NUM_FILTERS)(out_relu)\n",
    "pre_concat_28=Conv2DTranspose(128,(1,1),strides=(4,4))(out_relu)\n",
    "post_concat_28=tf.keras.layers.concatenate([pre_concat_28,block_6_output],axis=-1)\n",
    "\n",
    "head_28=Head(3*s*4*s*4*(c+5*b), (s*4,s*4,3,c+5*b),NUM_FILTERS)(post_concat_28)\n",
    "model=Model(inputs=inputs,outputs=[head_7,head_28])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c35420",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e26903",
   "metadata": {},
   "source": [
    "<H1>TRAINING</H1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb21263",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8696fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLOLoss(tf.losses.Loss):\n",
    "    def __init__(self,):\n",
    "        super(YOLOLoss,self).__init__()\n",
    "        pass\n",
    "    def call(self, y_true, y_pred):\n",
    "        cce = tf.keras.losses.CategoricalCrossentropy()\n",
    "        bce = tf.keras.losses.BinaryCrossentropy()\n",
    "        \n",
    "        target = tf.reshape(y_true[...,26], [-1])\n",
    "        predictions = tf.reshape(y_pred[...,26], [-1])\n",
    "\n",
    "        ###################### OBject Loss\n",
    "        y_pred_extract = tf.keras.activations.sigmoid(tf.gather(predictions, tf.reshape(tf.where(target==1),[-1])))\n",
    "        y_target_extract = tf.ones(len(y_pred_extract))\n",
    "        object_loss = bce(y_pred_extract,y_target_extract)\n",
    "\n",
    "        ####################### For No object\n",
    "\n",
    "        y_pred_extract = tf.keras.activations.sigmoid(tf.gather(predictions, tf.reshape(tf.where(target==0),[-1])))\n",
    "        y_target_extract = tf.zeros(len(y_pred_extract))\n",
    "        no_object_loss = bce(y_pred_extract,y_target_extract)\n",
    "\n",
    "        ####################### For OBject class loss\n",
    "\n",
    "        y_pred_extract = tf.nn.softmax(tf.gather_nd(y_pred,tf.where(y_true[...,25]!=0))[...,0:22])\n",
    "        y_target_extract = tf.gather_nd(y_true,tf.where(y_true[...,25]!=0))[...,0:22]\n",
    "\n",
    "        class_loss = cce(y_pred_extract,y_target_extract)\n",
    "\n",
    "        # ######################## For object bounding box loss\n",
    "\n",
    "        y_pred_extract_centre = tf.gather_nd(y_pred,tf.where(y_true[...,25]!=0))[...,22:24]\n",
    "        y_target_extract_centre = tf.gather_nd(y_true,tf.where(y_true[...,25]!=0))[...,22:24]\n",
    "\n",
    "\n",
    "\n",
    "        bounding_centre_loss = tf.math.reduce_mean(tf.keras.losses.mean_squared_error(y_pred_extract_centre, y_target_extract_centre))\n",
    "\n",
    "        y_pred_extract_side = tf.gather_nd(y_pred,tf.where(y_true[...,25]!=0))[...,24:26]\n",
    "        y_target_extract_side = tf.gather_nd(y_true,tf.where(y_true[...,25]!=0))[...,24:26]\n",
    "\n",
    "        bounding_side_loss = tf.math.reduce_mean(tf.keras.losses.mean_squared_error(y_pred_extract_side, y_target_extract_side))\n",
    "\n",
    "        bounding_loss = bounding_centre_loss + bounding_side_loss\n",
    "\n",
    "        lambda_coord = 5.\n",
    "        lambda_no_obj = 0.5\n",
    "\n",
    "        loss = object_loss + (lambda_no_obj*no_object_loss)+ tf.cast(lambda_coord*bounding_loss,dtype=tf.float32)+ tf.cast(class_loss,dtype=tf.float32) \n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0872a19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss = YOLOLoss(),\n",
    "    optimizer = Adam(learning_rate = LR),\n",
    "    run_eagerly = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8559844",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath='...'\n",
    "callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath = checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='loss',\n",
    "    mode='min',\n",
    "    save_best_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac24b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_gen,\n",
    "    verbose=1,\n",
    "    shuffle=True,\n",
    "    epochs=2500,\n",
    "    callbacks=[callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ef4899",
   "metadata": {},
   "source": [
    "<h1>TESTING</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b9da9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image ='...'\n",
    "X=[]\n",
    "anchor_noxes=[[1.3,1.3],[2.3,1.3],[1.3,2.3]]\n",
    "\n",
    "im = tf.keras.preprocessing.image.load_img(test_image,color_mode='rgb',target_size=(500,500))\n",
    "image_width,image_height=im.width,im.height\n",
    "im=tf.keras.preprocessing.image.img_to_array(image)/255.\n",
    "\n",
    "\n",
    "image = tf.keras.preprocessing.image.load_img(test_image,color_mode='rgb',target_size=(224,224))\n",
    "image=tf.keras.preprocessing.image.img_to_array(image)\n",
    "\n",
    "X.append(np.array(image))\n",
    "X=np.array(X)\n",
    "\n",
    "output=model.predict(X)\n",
    "\n",
    "final_boxes=[]\n",
    "object_classes=[]\n",
    "final_scores=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e0192b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_boxes(out,scales):\n",
    "    for scale in range(len(scales)):\n",
    "        split_size=scales[scale]\n",
    "        for a in range(len(anchor_boxes)):\n",
    "            output=out[scale][...,a,:]\n",
    "            THRESH=10\n",
    "            bounding_boxes=tf.where(output[...,26]>=THRESH)\n",
    "            selected_output=tf.gather_nd(output,bounding_boxes)\n",
    "            objects=tf.argmax(selected_output[...,0:22],axis=-1)\n",
    "            i=0\n",
    "            \n",
    "            for box in bounding_boxes:\n",
    "                box=np.array(box)\n",
    "                output_box=output[pos[0]][box[1]][box[2]][22:27]\n",
    "                final_scores.append(output_box[-1])\n",
    "\n",
    "                x_centre=int((image_width/split_size)*(tf.keras.activations.sigmoid(output_box[0])+box[1])\n",
    "                y_centre=int((image_height/split_size)*(tf.keras.activations.sigmoid(output_box[1])+box[2])\n",
    "                \n",
    "                x_width=int(image_width*anchor_boxes[a][0]*tf.math.exp(output_box[2]))\n",
    "                y_height=int(image_height*anchor_boxes[a][1]*tf.math.exp(output_box[3]))\n",
    "                \n",
    "                x_min=int(x_centre-(x_width/2))\n",
    "                y_min=int(y_centre-(y_height/2))\n",
    "\n",
    "                x_max=int(x_centre+(x_width/2))\n",
    "                y_max=int(y_centre+(y_height/2))\n",
    "\n",
    "                if(x_min<=0):x_min=0\n",
    "                if(y_min<=0):y_min=0\n",
    "                if(x_max>=image_width):x_max=image_width\n",
    "                if(y_max>=image_height):y_max=image_height\n",
    "\n",
    "                final_boxes.append([x_min,y_min,x_max,y_max,str(classes[objects[i]])])\n",
    "                i+=1\n",
    "    return np.array(final_boxes),np.array(final_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1231b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_size=7\n",
    "scales=[split_size,split_size*4]\n",
    "final_boxes,final_scores=get_boxes(out,scales)\n",
    "print('finalboxes',final_boxes)\n",
    "i=0\n",
    "\n",
    "object_classes=final_boxes[...,4]\n",
    "final_boxes=final_boxes[...,0:4]\n",
    "\n",
    "nms_output=tf.image.non_max_suppression(\n",
    "    final_boxes,final_scores,max_output_size=20,iou_threshold=0.5,\n",
    "    score_threshold=float('-inf')\n",
    ")\n",
    "\n",
    "final_nms_boxes=[]\n",
    "\n",
    "for i in nms_output:\n",
    "    final_nms_boxes.append(list(final_boxes[i]))\n",
    "i=0\n",
    "for i,box in enumerate(final_nms_boxes):\n",
    "    cv2.rectangle(image, (int(box[0]),int(box[1])),(int(box[2]),int(box[3])),(0,0,255),1)\n",
    "    cv2.putText(\n",
    "      image,\n",
    "      object_classes[i],\n",
    "      (int(box[0]),int(box[1])),\n",
    "      cv2.FONT_HERSHEY_SIMPLEX,1,(222,0,0),2\n",
    "      )\n",
    "cv2.imshow(\"YOU ONLY LOOK ONCE\",im)\n",
    "pause=cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0694be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou(bbox_1,bbox_2):\n",
    "    x_1=tf.maximum(bbox_1[0],bbox_2[0])\n",
    "    y_1=tf.maximum(bbox_1[1],bbox_2[1])\n",
    "    x_2=tf.maximum(bbox_1[2],bbox_2[2])\n",
    "    y_2=tf.maximum(bbox_1[3],bbox_2[3])\n",
    "    \n",
    "    inter_area=float(max(x_2-x_1,0)*max(y_2-y_1,0))\n",
    "    bbox_1_area=(bbox_1[2]-bbox_1[0])*(bbox_1[3]-bbox_1[1])\n",
    "    bbox_2_area=(bbox_2[2]-bbox_2[0])*(bbox_2[3]-bbox_2[1])1\n",
    "    \n",
    "    union_area=float(bbox_1_area+bbox_2_area-inter_area)\n",
    "    return inter_area/union_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0804f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def area_polygon(x,y):\n",
    "    area_1,area_2=0,0\n",
    "    for i in range(len(x)-1):\n",
    "        area_1+=x[i]*y[i+1]\n",
    "    area_1+=x[len(x)-1]*y[0]\n",
    "    \n",
    "    for i in range(len(x)-1):\n",
    "        area_2+=x[i+1]*y[i]\n",
    "    area_2+=x[0]*y[len(x)-1]\n",
    "    return 0.5*tf.abs(area_1-area_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f65e3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target(val_data):\n",
    "    THRESH=0.5\n",
    "    utils=Utils(7,1,classes)\n",
    "    bounding_boxes,image_shape=utils.preprocess_xml(val_data,m_a_p=True)\n",
    "    y_target=utils.generate_pre_output(bounding_boxes,image_shape)\n",
    "    return y_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5dc5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean(arr):\n",
    "    summ=0\n",
    "    for i in arr:\n",
    "        summ+=i\n",
    "    return summ/len(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d0d716",
   "metadata": {},
   "outputs": [],
   "source": [
    "aps=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0bba25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_average_precision():\n",
    "    for object_class in classes:\n",
    "        precision=[1.]\n",
    "        recall=[0.]\n",
    "        n_class=0\n",
    "        tp,fp=0,0\n",
    "        for image,bbox in zip(os.listdir(val_images),os.listdir(val_maps)):\n",
    "            y_target=get_target(val_maps+bbox)\n",
    "            for target in y_target:\n",
    "                if target[4]==object_class:\n",
    "                    n_class+=1\n",
    "        for image,bbox in zip(os.listdir(val_images),os.listdir(val_maps)):\n",
    "            y_target=get_target(val_maps+bbox)\n",
    "            y_pred=generate_output(val_images+image)\n",
    "            \n",
    "            for pred in y_pred:\n",
    "                if pred[4]!=object_class:\n",
    "                    pass\n",
    "                else:\n",
    "                    found=False\n",
    "                    for target in y_target[4] and iou(pred[:4],target[:4])>0.5:\n",
    "                        found=True\n",
    "                        break\n",
    "                    if found:\n",
    "                        tp+=1\n",
    "                    else:\n",
    "                        fp+=1\n",
    "                    if tp/(tp+fp)>1e-3 and tp/n_class>1e-3:\n",
    "                        precision.append(tp/(tp+fp))\n",
    "                        reacall.append(min(1.,tp/n_class))\n",
    "        precision.append(0.)\n",
    "        recall.append(max(recall))\n",
    "        precision.append(0.)\n",
    "        recall.append(0.)\n",
    "        \n",
    "        ap_s.append(area_polygon(recall,precision).numpy())\n",
    "    return mean(ap_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73146b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5954d55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78432d03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ab44cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e418acec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb1b261",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3e39e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698846d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34792b63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36fee44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5364c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ee0599",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

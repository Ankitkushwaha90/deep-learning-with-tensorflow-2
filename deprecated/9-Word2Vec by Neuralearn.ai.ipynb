{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223e425c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "from tensorflow.keras.preprocessing import text_dataset_from_directory\n",
    "from tensorflow.keras.layers import SimpleRNN,LSTM,Dense,GRU,Bidirectional,Reshape\n",
    "from tensorflow.data.experimental import AUTOTUNE\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "import datetime\n",
    "import numpy as np\n",
    "import gensim.downloader as api\n",
    "from tensorboard.plugins import projector\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas\n",
    "%reload_ext tensorboad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930fb329",
   "metadata": {},
   "outputs": [],
   "source": [
    "wv=api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c7bcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(wv.index_to_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aec3b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentences(input_data):\n",
    "    '''\n",
    "    Task: Preprocess sentences or standardize the sentences\n",
    "    Input: raw reviews\n",
    "    output: standardized reviews\n",
    "    '''\n",
    "    output=tf.strings.lower(input_data)\n",
    "    outputs=tf.strings.regex_replace(output,\"<[^>]+>\",\"\")\n",
    "    outputs=tf.strings.regex_replace(output,\"<[%s]\"%re.esceape(string.punctuation),\" \")\n",
    "    outputs=tf.strings.regex_replace(output,\"  \",\" \")\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20de85a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_index(word):\n",
    "    out=0\n",
    "    try:\n",
    "        out=wv.key_to_index[word]\n",
    "        if out<30000:\n",
    "            return out\n",
    "        else:\n",
    "            return 0\n",
    "    except:\n",
    "        try:\n",
    "            out=wv.key_to_index[word[0].upper()+word[1:]]\n",
    "            if out<30000:\n",
    "                return out\n",
    "            else:\n",
    "                return 0\n",
    "        except:\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fd6ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    \n",
    "    def __init__(self,train_pos,train_neg,vocab_size,sequence_length,batch_size,shuffle=False):\n",
    "        self.train_pos = train_pos\n",
    "        self.train_neg = train_neg\n",
    "        self.batch_size = batch_size\n",
    "        self.train_pos_list = os.listdir(train_pos)\n",
    "        self.train_neg_list = os.listdir(train_neg)\n",
    "        self.vocab_size = vocab_size\n",
    "        self.sequence_length = sequence_length\n",
    "        \n",
    "    def __getitem__(self,idx):\n",
    "        X,y=self.__data_generation(idx)\n",
    "        return X,y\n",
    "    def __data_generation(self,idx):\n",
    "\n",
    "        x=[]\n",
    "        y=[]\n",
    "\n",
    "        for j in range(idx*self.batch_size,(idx+1)*self.batch_size):\n",
    "            for t in range(2):\n",
    "                if t==0:\n",
    "                    with open(self.train_pos+self.train_pos_list[j],encoding=\"utf-8\") as f:\n",
    "                        for line in f:\n",
    "                            lin=line\n",
    "\n",
    "                else:\n",
    "                    with open(self.train_neg+self.train_neg_list[j],encoding=\"utf-8\") as f:\n",
    "                        for line in f:\n",
    "                            lin=line\n",
    "                rev=[]\n",
    "                for k,i in enumerate(tf.strings.split(preprocess_sentences(lin))):\n",
    "                    rev.append(word_index(str(i.numpy())[2:-1]))\n",
    "                    if k>=(250-1):\n",
    "                        break\n",
    "                out=tf.concat([tf.constant(rev),tf.zeros([self.sequence_length-len(rev)],dtype=tf.int32)],axis=0)\n",
    "                f.close()\n",
    "                X.append(list(out.numpy()))\n",
    "                \n",
    "                if t==0:\n",
    "                    y.append(1)\n",
    "                else:\n",
    "                    y.append(0)\n",
    "        return tf.constant(X),tf.constant(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3fe501",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos='...'\n",
    "train_neg='...'\n",
    "\n",
    "val_pos='...'\n",
    "val_neg='...'\n",
    "\n",
    "BATCH_SIZE=32\n",
    "LR=1E-4\n",
    "VOCAB_SIZE=30000\n",
    "SEQUENCE_LENGTH=250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d7ad35",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen=DataGenerator(train_pos,train_neg,VOCAB_SIZE,SEQUENCE_LENGTH,BATCH_SIZE)\n",
    "train_gen=DataGenerator(val_pos,val_neg,VOCAB_SIZE,SEQUENCE_LENGTH,BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb741bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix=[]\n",
    "\n",
    "for i in range(VOCAB_SIZE):\n",
    "    embedding_matrix.append(wv[i])\n",
    "embedding_matrix=np.array(embedding_matrix)\n",
    "print(embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caed3f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs=tf.keras.layers.Input(shape=(SEQUENCE_LENGTH,),)\n",
    "\n",
    "embedding=tf.keras.layers.Embedding(\n",
    "    VOCAB_SIZE,\n",
    "    300,\n",
    "    embeddings_initializer=tf.keras.initializers.Constant(embedding_matrix),\n",
    "    trainable=False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c222b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model=tf.keras.models.Sequential([\n",
    "    inputs,\n",
    "    embedding,\n",
    "    tf.keras.layers.Conv1D(256,kernel_size=2,activation='relu'),\n",
    "    tf.keras.layers.MaxPooling1D(2),\n",
    "    \n",
    "    tf.keras.layers.Conv1D(128,kernel_size=2,activation='relu'),\n",
    "    tf.keras.layers.MaxPooling1D(2),\n",
    "    \n",
    "    tf.keras.layers.GlobalMaxPooling1D(),\n",
    "    tf.keras.layers.Dense(1,activation='sigmoid',),\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8d0d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    optimizer=tf.keras.optimizers.Adam(lr=LR),\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7193b736",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath='...'\n",
    "log_dir='...'\n",
    "callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='loss',\n",
    "    mode='min',\n",
    "    save_best_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375d07e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_callback=tf.keras.callbacks.TensorBoard(log_dir=log_dir,histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0316c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "history=model.fit(train_gen,verbose=1,epochs=EPOCH,callbacks=[callback,t_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15454cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exist(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "    \n",
    "with open(os.path.join(log_dir,'metadaata.tsv'),\"w\",encodings=\"utf-8\") as f:\n",
    "    for i in range(VOCAB_SIZE):\n",
    "        f.write(\"{} {}\\n\".format(i,wv.index_to_key[i]))\n",
    "\n",
    "embedding_weights=tf.Variable(model.layers[0].get_weights()[0])\n",
    "checkpoint=tf.train.Checkpoint(embedding-embedding_weights)\n",
    "checkpoint.save(os.path.join(log_dir,\"embedding.ckpt\"))\n",
    "\n",
    "config=projector.ProjectorConfig()\n",
    "embedding=config.embeddings.add()\n",
    "\n",
    "embedding.metadata_path='metadata.tsv'\n",
    "projector.visualize_embeddings(log_dir,config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdaa94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --log_dir logs/imdb/fit/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f499781",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa25fcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8318b8fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7451f4ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891521ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8dbb90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8c0a06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83660f97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5629549",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

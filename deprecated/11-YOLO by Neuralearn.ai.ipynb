{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e105f643",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf### models\n",
    "import numpy as np### math computations\n",
    "import matplotlib.pyplot as plt### plotting bar chart\n",
    "import sklearn### machine learning library\n",
    "import cv2## image processing\n",
    "from sklearn.metrics import confusion_matrix, roc_curve### metrics\n",
    "import seaborn as sns### visualizations\n",
    "import datetime\n",
    "import pathlib\n",
    "import io\n",
    "import json\n",
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "from google.colab import files\n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras.layers import (GlobalAveragePooling2D, Activation, MaxPooling2D, Add, Conv2D, MaxPool2D, Dense,\n",
    "                                     Flatten, InputLayer, BatchNormalization, Input, Embedding, Permute,\n",
    "                                     Dropout, RandomFlip, RandomRotation, LayerNormalization, MultiHeadAttention,\n",
    "                                     RandomContrast, Rescaling, Resizing, Reshape,LeakyReLU)\n",
    "from tensorflow.keras.losses import BinaryCrossentropy,CategoricalCrossentropy, SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import Accuracy,TopKCategoricalAccuracy, CategoricalAccuracy, SparseCategoricalAccuracy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import (Callback, CSVLogger, EarlyStopping, LearningRateScheduler,\n",
    "                                        ModelCheckpoint, ReduceLROnPlateau)\n",
    "from tensorflow.keras.regularizers import L2, L1\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "from tensorflow.train import BytesList, FloatList, Int64List\n",
    "from tensorflow.train import Example, Features, Feature\n",
    "from google.colab import drive\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451711be",
   "metadata": {},
   "source": [
    "<H1>DATA PREPARATION</H1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c55e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Utils():\n",
    "    def __init__(self, split_size, num_boxes, classes):\n",
    "        self.split_size = split_size\n",
    "        self.num_boxes = num_boxes\n",
    "        self.classes = classes\n",
    "        \n",
    "    def preprocess_xml(self, filename,m_a_p=False):\n",
    "        tree = ET.parse(filename)\n",
    "        root = tree.getroot()\n",
    "        bounding_boxes = []\n",
    "\n",
    "        size_tree = root.find('size')\n",
    "        height = float(size_tree.find('height').text)\n",
    "        width = float(size_tree.find('width').text)\n",
    "\n",
    "        for object_tree in root.findall('object'):\n",
    "            for bounding_box in object_tree.iter('bndbox'):\n",
    "\n",
    "                xmin = (float(bounding_box.find('xmin').text)/width)\n",
    "                ymin = (float(bounding_box.find('ymin').text)/height)\n",
    "                xmax = (float(bounding_box.find('xmax').text)/width)\n",
    "                ymax = (float(bounding_box.find('ymax').text)/height)\n",
    "                if m_a_p:\n",
    "                    xmin=int(xmin*width)\n",
    "                    ymin=int(ymin*height)\n",
    "                    xmax=int(xmax*width)\n",
    "                    ymax=int(ymax*height)\n",
    "                break\n",
    "            class_name = object_tree.find('name').text\n",
    "            bounding_box = [xmin,ymin,xmax,ymax,class_name]\n",
    "            bounding_boxes.append(bounding_box)\n",
    "        if m_a_p:\n",
    "            return bounding_boxes,(height,width)\n",
    "    return bounding_boxes\n",
    "\n",
    "    def midpoint(self, x,y):\n",
    "        return (x+y)/2\n",
    "    def get_pos(self,classes, classe):\n",
    "        for c in range(len(classes)):\n",
    "            if(classes[c]==classe):\n",
    "                return c\n",
    "    def generate_output(self, bounding_boxes):\n",
    "        output_label = np.zeros((self.split_size, self.split_size, len(self.classes)+(5*self.num_boxes)))\n",
    "\n",
    "        for box in bounding_boxes:\n",
    "            x_min, y_min, x_max, y_max = box[0], box[1], box[2], box[3]\n",
    "\n",
    "            x_centre = self.midpoint(x_min, x_max)\n",
    "            y_centre = self.midpoint(y_min, y_max)\n",
    "\n",
    "            x_width = x_max - x_min\n",
    "            y_height = y_max - y_min\n",
    "\n",
    "            i = int(x_centre*self.split_size)\n",
    "            j = int(y_centre*self.split_size)\n",
    "\n",
    "            x_centre_cell = (x_centre*self.split_size)-i\n",
    "            y_centre_cell = (y_centre*self.split_size)-j\n",
    "\n",
    "            if(output_label[i,j,26]==0):\n",
    "                output_label[i,j,22:27] = np.array([x_centre_cell, y_centre_cell, x_width,y_height,1])\n",
    "                output_label[i,j,self.get_pos(self.classes, box[4])] = 1.0\n",
    "        return output_label\n",
    "    def generate_pre_output(self,bounding_boxes,image_shape):\n",
    "        height,width=image_shape\n",
    "        bbox=[]\n",
    "        for box in bounding_boxes:\n",
    "            x_min,y_min,x_max,y_max,obj=box[0],box[1],box[2],box[3],box[4]\n",
    "            bbox.append([int(x_min/width*224),int(y_min/height*224),int(x_max/width*224),int(y_max/height*224),obj])\n",
    "        return bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cf4828",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image='...'\n",
    "image = tf.keras.preprocessing.image.load_img(\n",
    "    test_image,color_mode='rgb',target_size=(224,224)\n",
    ")\n",
    "classes = ['background','aeroplane','bicycle','bird','boat','bottle','bus','car','cat',\n",
    "           'chair','cow','diningtable','dog','horse','motorbike','person','pottedplant',\n",
    "           'sheep','sofa','train','tvmonitor','book']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96473d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__ (self, train_images, train_maps, split_size, num_boxes, classes, batch_size, shuffle = False):\n",
    "\n",
    "        self.train_images = train_images\n",
    "        self.train_maps = train_maps\n",
    "        self.train_image_list = os.listdir(self.train_images)\n",
    "        self.train_map_list = os.listdir(self.train_maps)\n",
    "        self.split_size = split_size\n",
    "        self.num_boxes = num_boxes\n",
    "        self.classes = classes\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.train_image_list)/self.batch_size))\n",
    "  \n",
    "    def __getitem__(self, idx):\n",
    "        x,y = self.__data_generation(idx)\n",
    "        return np.array(x), np.array(y)\n",
    "  \n",
    "    def __data_generation(self, idx):\n",
    "        x = np.empty((self.batch_size, 224,224,3))\n",
    "        y = np.zeros((self.batch_size, self.split_size, self.split_size,27))\n",
    "\n",
    "        for i,j in enumerate(list(range(idx*self.batch_size, (idx+1)*self.batch_size))):\n",
    "            image = tf.keras.preprocessing.image.load_img(self.train_images + self.train_image_list[j],\n",
    "                                                        color_mode ='rgb', target_size = (224,224))\n",
    "            x[i] = tf.keras.preprocessing.image.img_to_array(image)\n",
    "            utils = Utils(self.split_size,self.num_boxes,self.classes)\n",
    "            bounding_boxes = utils.preprocess_xml(self.train_maps+self.train_map_list[j])\n",
    "            y[i] = utils.generate_output(bounding_boxes)\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b125672d",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR=1e-3\n",
    "BATCH_SIZE=32\n",
    "EPOCH=100\n",
    "train_images='...'\n",
    "train_maps='...'\n",
    "val_images='...'\n",
    "val_maps='...'\n",
    "split_size=7\n",
    "num_boxes=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decf38a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = DataGenerator(train_images, train_maps, split_size, num_boxes, classes, batch_size=BATCH_SIZE)\n",
    "val_gen = DataGenerator(val_images, val_maps, split_size, num_boxes, classes, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b789875",
   "metadata": {},
   "source": [
    "<H1>MODELING</H1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed044d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = 224\n",
    "NUM_FILTERS = 16\n",
    "\n",
    "s = split_size\n",
    "c = len(classes)\n",
    "b = num_boxes\n",
    "\n",
    "OUTPUT_DIM  = s*s*(c+5*b)\n",
    "OUTPUT_SHAPE = (s,s,c+5*b)\n",
    "\n",
    "inputs = tf.keras.Input(shape = (INPUT_DIM, INPUT_DIM, 3))\n",
    "\n",
    "base_model = tf.keras.applications.mobilenet_v2.MobileNetV2(\n",
    "    weights='imagenet',\n",
    "    input_shape=(INPUT_DIM,INPUT_DIM,3),\n",
    "    include_top=False,\n",
    ")\n",
    "\n",
    "base_model.trainable=False\n",
    "\n",
    "model=tf.keras.Sequential([\n",
    "                        \n",
    "    inputs,\n",
    "    base_model,\n",
    "    Conv2D(NUM_FILTERS,(3,3),kernel_initializer=RandomNormal(0.01)),\n",
    "    LeakyReLU(alpha=0.1),\n",
    "    Conv2D(NUM_FILTERS/2,(3,3),kernel_initializer=RandomNormal(0.01)),\n",
    "    LeakyReLU(alpha=0.1),\n",
    "    LayerNormalization(),\n",
    "    Conv2D(OUTPUT_DIM,(3,3),kernel_initializer=RandomNormal(0.01)),\n",
    "    LeakyReLU(alpha=0.1),\n",
    "    Flatten(),\n",
    "\n",
    "    Dense(OUTPUT_DIM),\n",
    "    Reshape(OUTPUT_SHAPE),\n",
    "              \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c35420",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e26903",
   "metadata": {},
   "source": [
    "<H1>TRAINING</H1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb21263",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41af8c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLOLoss(tf.losses.Loss):\n",
    "    def __init__(self,):\n",
    "        super(YOLOLoss,self).__init__()\n",
    "        pass\n",
    "    def call(self, y_true, y_pred):\n",
    "        cce = tf.keras.losses.CategoricalCrossentropy()\n",
    "        bce = tf.keras.losses.BinaryCrossentropy()\n",
    "        \n",
    "        target = tf.reshape(y_true[...,26], [-1])\n",
    "        predictions = tf.reshape(y_pred[...,26], [-1])\n",
    "\n",
    "        ###################### OBject Loss\n",
    "        y_pred_extract = tf.keras.activations.sigmoid(tf.gather(predictions, tf.reshape(tf.where(target==1),[-1])))\n",
    "        y_target_extract = tf.ones(len(y_pred_extract))\n",
    "        object_loss = bce(y_pred_extract,y_target_extract)\n",
    "\n",
    "        ####################### For No object\n",
    "\n",
    "        y_pred_extract = tf.keras.activations.sigmoid(tf.gather(predictions, tf.reshape(tf.where(target==0),[-1])))\n",
    "        y_target_extract = tf.zeros(len(y_pred_extract))\n",
    "\n",
    "\n",
    "        no_object_loss = bce(y_pred_extract,y_target_extract)\n",
    "\n",
    "        ####################### For OBject class loss\n",
    "\n",
    "        y_pred_extract = tf.nn.softmax(tf.gather_nd(y_pred,tf.where(y_true[...,26]==1))[...,0:22])\n",
    "        y_target_extract = tf.gather_nd(y_true,tf.where(y_true[...,26]==1))[...,0:22]\n",
    "\n",
    "        class_loss = cce(y_pred_extract,y_target_extract)\n",
    "\n",
    "        # ######################## For object bounding box loss\n",
    "\n",
    "        y_pred_extract_centre = tf.gather_nd(y_pred,tf.where(y_true[...,26]==1))[...,22:24]\n",
    "        y_target_extract_centre = tf.gather_nd(y_true,tf.where(y_true[...,26]==1))[...,22:24]\n",
    "\n",
    "\n",
    "\n",
    "        bounding_centre_loss = tf.math.reduce_mean(tf.keras.losses.mean_squared_error(y_pred_extract_centre, y_target_extract_centre))\n",
    "\n",
    "        y_pred_extract_side = tf.gather_nd(y_pred,tf.where(y_true[...,26]==1))[...,24:26]\n",
    "        y_target_extract_side = tf.gather_nd(y_true,tf.where(y_true[...,26]==1))[...,24:26]\n",
    "\n",
    "        bounding_side_loss = tf.math.reduce_mean(tf.keras.losses.mean_squared_error(y_pred_extract_side, y_target_extract_side))\n",
    "\n",
    "        bounding_loss = bounding_centre_loss + bounding_side_loss\n",
    "\n",
    "        lambda_coord = 5.\n",
    "        lambda_no_obj = 0.5\n",
    "\n",
    "        loss = object_loss + (lambda_no_obj*no_object_loss)+ tf.cast(lambda_coord*bounding_loss,dtype=tf.float32)+ tf.cast(class_loss,dtype=tf.float32) \n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0872a19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss = YOLOLoss(),\n",
    "    optimizer = Adam(learning_rate = LR),\n",
    "    run_eagerly = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8559844",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath='...'\n",
    "callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath = checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='loss',\n",
    "    mode='min',\n",
    "    save_best_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac24b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_gen,\n",
    "    verbose=1,\n",
    "    shuffle=True,\n",
    "    epochs=2500,\n",
    "    callbacks=[callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ef4899",
   "metadata": {},
   "source": [
    "<h1>TESTING</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b9da9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image ='...'\n",
    "image = tf.keras.preprocessing.image.load_img(\n",
    "    test_image,color_mode='rgb',target_size=(224,224)\n",
    ")\n",
    "image_width,image_height=224,224\n",
    "im=tf.keras.preprocessing.image.img_to_array(image)/255.\n",
    "image=tf.keras.preprocessing.image.img_to_array(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e0192b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output=model.predict(tf.expand_dims(image, axis=0))\n",
    "THRESH=5\n",
    "object_positions=tf.where(output[...,26]>=THRESH)\n",
    "selected_output=tf.gather_nd(output,object_positions)\n",
    "objects=tf.argmax(selected_output[...,0:22],axis=-1)\n",
    "\n",
    "final_boxes=[]\n",
    "object_classes=[]\n",
    "final_scores=[]\n",
    "\n",
    "for i,pos in enumerate(object_positions):\n",
    "    pos=np.array(pos)\n",
    "    output_box=output[pos[0]][pos[1]][pos[2]][22:27]\n",
    "    final_scores.append(output_box[-1])\n",
    "\n",
    "    x_centre=(image_width/split_size)*(output_box[0]+pos[1])\n",
    "    y_centre=(image_height/split_size)*(output_box[1]+pos[2])\n",
    "\n",
    "    x_width=image_width*output_box[2]\n",
    "    y_height=image_height*output_box[3]\n",
    "\n",
    "    x_min=int(x_centre-(x_width/2))\n",
    "    y_min=int(y_centre-(y_height/2))\n",
    "\n",
    "    x_max=int(x_centre+(x_width/2))\n",
    "    y_max=int(y_centre+(y_height/2))\n",
    "\n",
    "    if(x_min<=0):x_min=0\n",
    "    if(y_min<=0):y_min=0\n",
    "    if(x_max>=image_width):x_max=image_width\n",
    "    if(y_max>=image_height):y_max=image_height\n",
    "\n",
    "    final_boxes.append([x_min,y_min,x_max,y_max,str(classes[objects[i]])])\n",
    "\n",
    "print('finalboxes',final_boxes)\n",
    "\n",
    "final_boxes=np.array(final_boxes)\n",
    "final_scores=np.array(final_scores)\n",
    "\n",
    "object_classes=final_boxes[...,4]\n",
    "final_boxes=final_boxes[...,0:4]\n",
    "\n",
    "nms_output=tf.image.non_max_suppression(\n",
    "    final_boxes,final_scores,max_output_size=20,iou_threshold=0.5,\n",
    "    score_threshold=float('-inf')\n",
    ")\n",
    "\n",
    "final_nms_boxes=[]\n",
    "\n",
    "for i in nms_output:\n",
    "    final_nms_boxes.append(list(final_boxes[i]))\n",
    "\n",
    "for i,box in enumerate(final_nms_boxes):\n",
    "    cv2.rectangle(image, (int(box[0]),int(box[1])),(int(box[2]),int(box[3])),(0,0,255),1)\n",
    "    cv2.putText(\n",
    "      image,\n",
    "      object_classes[i],\n",
    "      (int(box[0]),int(box[1])),\n",
    "      cv2.FONT_HERSHEY_SIMPLEX,1,(222,0,0),2\n",
    "      )\n",
    "cv2.imshow(\"YOU ONLY LOOK ONCE\",im)\n",
    "pause=cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0694be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou(bbox_1,bbox_2):\n",
    "    x_1=tf.maximum(bbox_1[0],bbox_2[0])\n",
    "    y_1=tf.maximum(bbox_1[1],bbox_2[1])\n",
    "    x_2=tf.maximum(bbox_1[2],bbox_2[2])\n",
    "    y_2=tf.maximum(bbox_1[3],bbox_2[3])\n",
    "    \n",
    "    inter_area=float(max(x_2-x_1,0)*max(y_2-y_1,0))\n",
    "    bbox_1_area=(bbox_1[2]-bbox_1[0])*(bbox_1[3]-bbox_1[1])\n",
    "    bbox_2_area=(bbox_2[2]-bbox_2[0])*(bbox_2[3]-bbox_2[1])1\n",
    "    \n",
    "    union_area=float(bbox_1_area+bbox_2_area-inter_area)\n",
    "    return inter_area/union_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0804f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def area_polygon(x,y):\n",
    "    area_1,area_2=0,0\n",
    "    for i in range(len(x)-1):\n",
    "        area_1+=x[i]*y[i+1]\n",
    "    area_1+=x[len(x)-1]*y[0]\n",
    "    \n",
    "    for i in range(len(x)-1):\n",
    "        area_2+=x[i+1]*y[i]\n",
    "    area_2+=x[0]*y[len(x)-1]\n",
    "    return 0.5*tf.abs(area_1-area_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f65e3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target(val_data):\n",
    "    THRESH=0.5\n",
    "    utils=Utils(7,1,classes)\n",
    "    bounding_boxes,image_shape=utils.preprocess_xml(val_data,m_a_p=True)\n",
    "    y_target=utils.generate_pre_output(bounding_boxes,image_shape)\n",
    "    return y_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c498aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean(arr):\n",
    "    summ=0\n",
    "    for i in arr:\n",
    "        summ+=i\n",
    "    return summ/len(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1020027",
   "metadata": {},
   "outputs": [],
   "source": [
    "aps=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7955aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_average_precision():\n",
    "    for object_class in classes:\n",
    "        precision=[1.]\n",
    "        recall=[0.]\n",
    "        n_class=0\n",
    "        tp,fp=0,0\n",
    "        for image,bbox in zip(os.listdir(val_images),os.listdir(val_maps)):\n",
    "            y_target=get_target(val_maps+bbox)\n",
    "            for target in y_target:\n",
    "                if target[4]==object_class:\n",
    "                    n_class+=1\n",
    "        for image,bbox in zip(os.listdir(val_images),os.listdir(val_maps)):\n",
    "            y_target=get_target(val_maps+bbox)\n",
    "            y_pred=generate_output(val_images+image)\n",
    "            \n",
    "            for pred in y_pred:\n",
    "                if pred[4]!=object_class:\n",
    "                    pass\n",
    "                else:\n",
    "                    found=False\n",
    "                    for target in y_target[4] and iou(pred[:4],target[:4])>0.5:\n",
    "                        found=True\n",
    "                        break\n",
    "                    if found:\n",
    "                        tp+=1\n",
    "                    else:\n",
    "                        fp+=1\n",
    "                    if tp/(tp+fp)>1e-3 and tp/n_class>1e-3:\n",
    "                        precision.append(tp/(tp+fp))\n",
    "                        reacall.append(min(1.,tp/n_class))\n",
    "        precision.append(0.)\n",
    "        recall.append(max(recall))\n",
    "        precision.append(0.)\n",
    "        recall.append(0.)\n",
    "        \n",
    "        ap_s.append(area_polygon(recall,precision).numpy())\n",
    "    return mean(ap_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2d45c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c626a45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97966450",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d179eac1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cfdbe5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdc8f80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9ead2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d52ebd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac8ba96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb5081f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7118c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c100b414",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

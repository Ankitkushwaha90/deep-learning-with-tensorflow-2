{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e105f643",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf### models\n",
    "import numpy as np### math computations\n",
    "import matplotlib.pyplot as plt### plotting bar chart\n",
    "import sklearn### machine learning library\n",
    "import cv2## image processing\n",
    "import scipy.io\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.applications import VGG16,ResNet50\n",
    "from tensorflow.keras.layers import (GlobalAveragePooling2D, Activation, MaxPooling2D, Add, Conv2D, MaxPool2D, Dense,\n",
    "                                     Flatten, InputLayer, BatchNormalization, Input, Embedding, Permute,\n",
    "                                     Dropout, RandomFlip, RandomRotation, LayerNormalization, MultiHeadAttention,\n",
    "                                     RandomContrast, Rescaling, Resizing, Reshape,LeakyReLU)\n",
    "from tensorflow.keras.losses import BinaryCrossentropy,CategoricalCrossentropy, SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import Accuracy,TopKCategoricalAccuracy, CategoricalAccuracy, SparseCategoricalAccuracy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import (Callback, CSVLogger, EarlyStopping, LearningRateScheduler,\n",
    "                                        ModelCheckpoint, ReduceLROnPlateau)\n",
    "from tensorflow.keras.regularizers import L2, L1\n",
    "from tensorflow.keras.initializers import RandomNormal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451711be",
   "metadata": {},
   "source": [
    "<H1>DATA PREPARATION</H1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c55e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=32\n",
    "INPUT_DIM=224\n",
    "NUM_EPOCHS=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbf61a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_directory='...'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cf4828",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset=tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_directory,\n",
    "    validation_split=0.1,\n",
    "    subset='training',\n",
    "    seed=999,\n",
    "    image_size=(INPUT_DIM,INPUT_DIM),\n",
    "    batch_size=BATCH_SIZE,)\n",
    "val_dataset=tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_directory,\n",
    "    validation_split=0.1,\n",
    "    subset='validation',\n",
    "    seed=999,\n",
    "    image_size=(INPUT_DIM,INPUT_DIM),\n",
    "    batch_size=BATCH_SIZE,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052c2f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names=train_dataset.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fce8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c60eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "for images,labels in train_dataset.take(1):\n",
    "    for i in range(BATCH_SIZE):\n",
    "        ax=plt.subplot(BATCH_SIZE//8,BATCH_SIZE//4,i+1)\n",
    "        plt.imshow(images[i]/255.)\n",
    "        plt.title(class_names[labels[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c234bc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset=train_dataset.prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3eb388",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset=val_dataset.prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b789875",
   "metadata": {},
   "source": [
    "<H1>MODELING</H1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed044d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = ResNet50(\n",
    "        weights='imagenet',\n",
    "        input_shape=(INPUT_DIM,INPUT_DIM,3),\n",
    "        include_top=False,)\n",
    "backbone.trainable=False\n",
    "model=Sequential([\n",
    "    Input(shape=(224,224,3)),\n",
    "    backbone,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(1,activation='sigmoid'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c35420",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e26903",
   "metadata": {},
   "source": [
    "<H1>TRAINING</H1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f1282a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bce_loss=BinaryCrossentropy()\n",
    "optimizer=Adam(lr=1e-3)\n",
    "\n",
    "train_accuracy=BinaryAccuracy()\n",
    "val_accuracy=BinaryAccuracy()\n",
    "\n",
    "train_tp=TruePositives()\n",
    "val_tp=TruePositives()\n",
    "\n",
    "train_tn=TrueNegatives()\n",
    "val_tn=TrueNegatives()\n",
    "\n",
    "train_fp=FalsePositives()\n",
    "val_fp=FalsePositives()\n",
    "\n",
    "train_fn=FalseNegatives()\n",
    "val_fn=FalseNegatives()\n",
    "\n",
    "train_precision=Precision()\n",
    "val_precision=Precision()\n",
    "\n",
    "train_recall=Recall()\n",
    "val_recall=Recall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7660367b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(x,y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred=model(x,training=True)\n",
    "        loss_value=bce_loss(y,y_pred)\n",
    "    gradients=tape.gradient(loss_value,model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(gradients,model.trainable_weights))\n",
    "    \n",
    "    train_accuracy.update_state(y,y_pred)\n",
    "    train_tp.update_state(y,y_pred)\n",
    "    train_tn.update_state(y,y_pred)\n",
    "    train_fp.update_state(y,y_pred)\n",
    "    train_fn.update_state(y,y_pred)\n",
    "    train_precision.update_state(y,y_pred)\n",
    "    train_recall.update_state(y,y_pred)\n",
    "    \n",
    "    return loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0872a19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def val_step(x,y):\n",
    "    y_pred=model(x,training=False)\n",
    "    loss_value=bce_loss(y,y_pred)\n",
    "    val_accuracy.update_state(y,y_pred)\n",
    "    val_tp.update_state(y,y_pred)\n",
    "    val_tn.update_state(y,y_pred)\n",
    "    val_fp.update_state(y,y_pred)\n",
    "    val_fn.update_state(y,y_pred)\n",
    "    val_precision.update_state(y,y_pred)\n",
    "    val_recall.update_state(y,y_pred)\n",
    "    \n",
    "    return loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8559844",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(NUM_EPOCHS):\n",
    "    for (x_train,y_train) in train_dataset:\n",
    "        train_loss=train_step(x_train,y_train)\n",
    "    for (x_val,y_val) in val_dataset:\n",
    "        val_loss=val_step(x_val,y_val)\n",
    "    template='Epoch {}, Loss: {:.2f}, Accuracy: {:.2f}, Precision: {:.2f}, Recall: {:.2f}\\n '\n",
    "    print(template.format(epoch+1,\n",
    "                         train_loss,train_accuracy.result()*100,train_precision.result()*100,train_recall.result()*100))\n",
    "    \n",
    "    print('-------------------------------------------------------------------------------------')\n",
    "    print('            TP: {} --------------            FP:{}         --------------------'.format(train_tp.result(),train_fp.result()))\n",
    "    print('-------------------------------------------------------------------------------------')\n",
    "    print('            FN: {} --------------            TN:{}         --------------------'.format(train_fn.result(),train_tn.result()))\n",
    "    print('-------------------------------------------------------------------------------------')\n",
    "\n",
    "    template='Validation Loss: {:.2f}, Validation Accuracy: {:.2f}, Validation Precision: {:.2f}, Validation Recall: {:.2f}\\n '\n",
    "    print(template.format(val_loss,val_accuracy.result()*100,val_precision.result()*100,val_recall.result()*100))\n",
    "    \n",
    "    print('-------------------------------------------------------------------------------------')\n",
    "    print('            Val TP: {} --------------          Val FP:{}         --------------------'.format(val_tp.result(),val_fp.result()))\n",
    "    print('-------------------------------------------------------------------------------------')\n",
    "    print('            Val FN: {} --------------          Val TN:{}         --------------------'.format(val_fn.result(),val_tn.result()))\n",
    "    print('-------------------------------------------------------------------------------------')\n",
    "    \n",
    "    train_accuracy.reset_states()\n",
    "    train_tp.reset_states()\n",
    "    train_tn.reset_states()\n",
    "    train_fp.reset_states()\n",
    "    train_fn.reset_states()\n",
    "    train_precision.reset_states()\n",
    "    train_recall.reset_states()\n",
    "    \n",
    "    val_accuracy.reset_states()\n",
    "    val_tp.reset_states()\n",
    "    val_tn.reset_states()\n",
    "    val_fp.reset_states()\n",
    "    val_fn.reset_states()\n",
    "    val_precision.reset_states()\n",
    "    val_recall.reset_states()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac8ba96",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val=[]\n",
    "x_val=[]\n",
    "\n",
    "for x,y in val_dataset:\n",
    "    x_val.append(x)\n",
    "    y_val.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7118c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true=tf.stack(y_val,axis=0)[0]\n",
    "y_pred=model.predict(tf.stack(x_val,axis=0)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c100b414",
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc(labels,predictions):\n",
    "    fp,tp,_=sklearn.metrics.roc_curve(labels,predictions)\n",
    "    plt.plot(fp,tp)\n",
    "    plt.xlabel('false positives rate')\n",
    "    plt.ylabel('true positives rate')\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0820d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc(y_true,y_pred[...,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ef4899",
   "metadata": {},
   "source": [
    "<h1>TESTING</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a560e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_array=img_to_array(load_img(image,target_size=(INPUT_DIM,INPUT_DIM)))\n",
    "if mode.prdict(tf.expand_dims(im_array,axis=0))[0][0]<0.5:\n",
    "    print('its benign')\n",
    "else:\n",
    "    print('malignant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf529079",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

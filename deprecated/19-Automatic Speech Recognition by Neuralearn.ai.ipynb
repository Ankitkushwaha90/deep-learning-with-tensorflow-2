{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e105f643",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "from tensorflow.keras.preprocessing import text_dataset_from_directory\n",
    "from tensorflow.keras.layers import(SimpleRNN,Embedding,Input,LSTM,Input,Conv1D,Softmax\n",
    "                                    Dropout,Dense,GRU,LayerNormalization,Reshape,\n",
    "                                    Bidirectional,Reshape)\n",
    "from tensorflow.data.experimental import AUTOTUNE\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "import datetime\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451711be",
   "metadata": {},
   "source": [
    "<H1>DATA PREPARATION</H1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96473d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "path='...'\n",
    "text_path='...'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decf38a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_tet={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fcff9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(text_path, encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        i=line.strip().split(\"|\")[0]\n",
    "        text=line.strip().split(\"|\")[1]\n",
    "        audio_text[str(i)]=text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844da811",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_audio(audio_binary):\n",
    "    audio,_=tf.audio.decode_wav(audio_binary)\n",
    "    return tf.squeeze(audio,axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175a35c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spec(filepath):\n",
    "    label=audio_text[os.path.basename(file_path)[:-4]]\n",
    "    \n",
    "    audio_binary=tf.io.read_file(filepath)\n",
    "    waveform=decode_audio(audio_binary)\n",
    "    \n",
    "    zero_padding=(222621-len(waveform))*[0]\n",
    "    zero_padding=tf.constant(zero_padding,tf.float32)\n",
    "    \n",
    "    waveform=tf.cast(waveform,tf.float32)\n",
    "    equal_length=tf.concat([waveform,zero_padding],axis=0)\n",
    "    \n",
    "    spectrogram=tf.signal.stft(\n",
    "        equal_length,frame_length=63,frame_step=32)\n",
    "    spectrogram=tf.abs(spectrogram)\n",
    "    return tf.expand_dims(spectrogram,axis=-1),label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5720da8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary=[\" \",\"UNK\",\".\",\",\",\"?\"]+[chr(i) for i in range(97,97+26)]+[\"PAD\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21332947",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocab(char):\n",
    "    if char in vocabulary:\n",
    "        return vocabulary.index(char)\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b2393a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(label,seq_len=192):\n",
    "    label=label[:190]\n",
    "    out_label=[get_vocab(i.lower()) for i in label]\n",
    "    out_label=tf.constant(out_label)\n",
    "    return out_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12cb5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self,train_images,batch_size,SEQUENCE_LENGTH,VOCAB_SIZE,shuffle=False):\n",
    "        self.train_images=train_images\n",
    "        self.batch_size=batch_size\n",
    "        self.train_image_list=os.listdir(train_images)\n",
    "        self.SEQUENCE_LENGTH=SEQUENCE_LENGTH\n",
    "        self.VOCAB_SIZE=VOCAB_SIZE\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.train_image_list)/self.batch_size))\n",
    "    def __getitem__(self,idx):\n",
    "        X,y=self.__data_generation(idx)\n",
    "        return X,y\n",
    "    def __data_generation(self,idx):\n",
    "        X=[]\n",
    "        y=[]\n",
    "        for j in range(idx*self.batch_size,(idx+1)*self.batch_size):\n",
    "            spec,label=get_spec(self.train_images+self.train_image_list[j])\n",
    "            X.append(spec)\n",
    "            label=get_label(label,self.SEQUENCE_LENGTH)\n",
    "            y.append(label)\n",
    "        return tf.convert_to_tensor(X),tf.convert_to_tensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497a846b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path='...'\n",
    "BATCH_SIZE=1\n",
    "SEQUENCE_LENGTH=192\n",
    "VOCAB_SIZE=1\n",
    "LR=1e-3\n",
    "EPOCH=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d377688",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen=DataGenerator(train_path,BATCH_SIZE,SEQUENCE_LENGTH,VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b789875",
   "metadata": {},
   "source": [
    "<H1>MODELING</H1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1a21ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_layer=tf.keras.layers.experimental.preprocessing.Normalization()\n",
    "input_shape=(6955,33,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ce12e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential([\n",
    "    Input(shape=input_shape),\n",
    "    norm_layer,\n",
    "    Conv2D(512,3,padding='same',activation='relu'),\n",
    "    Conv2D(256,3,padding='same',activation='relu'),\n",
    "    \n",
    "    MaxPooling2D(),\n",
    "    Reshape((SEQUENCE_LENGTH,-1)),\n",
    "    Conv1D(len(vocabulary),3,padding='same'),\n",
    "    Softmax(axis=2),\n",
    "    \n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b00fe86",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e9fad1",
   "metadata": {},
   "source": [
    "<H1>TRAINING</H1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73ac783",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ctc_loss(y_true,y_pred):\n",
    "    batch_size=tf.shape(y_pred)[0]\n",
    "    pred_length=tf.shape(y_pred)[1]\n",
    "    true_length=tf.shape(y_true)[1]\n",
    "    \n",
    "    pred_length=pred_length*tf.ones([batch_size,1])\n",
    "    true_length=true_length*tf.ones([batch_size,1])\n",
    "    \n",
    "    return tf.keras.backend.ctc_batch_cost(y_true,y_pred,pred_length,true_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0872a19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=ctc_loss,\n",
    "    optimizer=tf.keras.optimizers.Adam(lr=LR,),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8559844",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath='...'\n",
    "callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='loss',\n",
    "    mode='min',\n",
    "    save_best_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac24b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "history=model.fit(train_gen,verbose=1, shuffle=True,epochs=EPOCH,callbacks=[callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4f5e6c",
   "metadata": {},
   "source": [
    "<h1>TESTING</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b9da9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_str='...'\n",
    "test_path='...'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e0192b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrogram,_=get_spec(test_path)\n",
    "out=tf.argmax(model.predict(tf.expand_dims(spectrogram,axis=0))[0],axis=1)\n",
    "out=[vocabulary[i] for i in out]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0694be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_str=\"\"\n",
    "for i in out:\n",
    "    out_str+=i\n",
    "pritn(out_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0804f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(y_pred):\n",
    "    batch_size=tf.shape(y_pred)[0]\n",
    "    \n",
    "    pred_length=tf.shape(y_pred)[1]\n",
    "    pred_length*=tf.ones([batch_size,],dtype=tf.int32)\n",
    "    \n",
    "    y_pred=tf.one_hot(y_pred,32)\n",
    "    output=tf.keras.backend.ctc_decode(y_pred,input_length=pred_length,greedy=True)[0][0]\n",
    "    \n",
    "    out=[vocabulary[i] fro i in output[0]]\n",
    "    out_str=\"\"\n",
    "    for i in out:\n",
    "        out_str+=i\n",
    "    return out_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05c239d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrogram,_=get_spec(test_path)\n",
    "out=tf.argmax(model.predict(tf.expand_dims(spectrogram,axis=0))[0],axis=1)\n",
    "decode(tf.expand_dims(out,axis=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
